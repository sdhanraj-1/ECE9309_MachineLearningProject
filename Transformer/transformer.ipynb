{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d664a8f3-deb0-47ee-96dd-4a094ba076f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\steph\\miniforge3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60393e37-8f4c-4abc-866f-024d0d1d697c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (280, 8), Validation: (80, 8), Test: (40, 8)\n"
     ]
    }
   ],
   "source": [
    "# train 70%, val 20%, test 10%\n",
    "df = pd.read_csv(\"database_clean.csv\")\n",
    "df = df.dropna(subset=['title', 'abstract'])\n",
    "df = df.head(400)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, X_temp = train_test_split(df, test_size=0.3, random_state=42)\n",
    "X_val, X_test = train_test_split(X_temp, test_size=1/3, random_state=42)\n",
    "print(f\"Train: {X_train.shape}, Validation: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0718d3bf-0782-450d-8a8b-ef1130b0bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/distiluse-base-multilingual-cased-v1\")\n",
    "\n",
    "class PaperDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title = str(self.data.iloc[idx][\"title\"])\n",
    "        abstract = str(self.data.iloc[idx][\"abstract\"])\n",
    "        input_text = title + \" \" + abstract  # Combine title and abstract\n",
    "        \n",
    "        tokens = self.tokenizer(\n",
    "            input_text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": tokens[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": tokens[\"attention_mask\"].squeeze(0),\n",
    "            \"paper_index\": idx  # Used for retrieval\n",
    "        }\n",
    "\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "dataset_train = PaperDataset(X_train, tokenizer, 256)\n",
    "dataloader = DataLoader(dataset_train, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f242b441-9990-4523-92cc-243e5fa7facb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Input IDs Shape: torch.Size([8, 256])\n",
      "Batch Attention Mask Shape: torch.Size([8, 256])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(\"Batch Input IDs Shape:\", batch[\"input_ids\"].shape)\n",
    "    print(\"Batch Attention Mask Shape:\", batch[\"attention_mask\"].shape)\n",
    "    break  # Check only the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50964c3e-9433-4a3a-8fa7-40b5575ca93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperRecommender(nn.Module):\n",
    "    def __init__(self, model_name=\"sentence-transformers/distiluse-base-multilingual-cased-v1\", embedding_dim=768, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.fc = nn.Linear(self.embedding_dim, embedding_dim)  # Projection layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.normalize = nn.functional.normalize  # L2 normalization for retrieval\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        input_ids = input_ids.to(next(self.parameters()).device)  # Ensure inputs are on the same device as the model\n",
    "        attention_mask = attention_mask.to(next(self.parameters()).device)\n",
    "        \n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # CLS token representation\n",
    "        embedding = self.fc(self.dropout(pooled_output))\n",
    "        return self.normalize(embedding, p=2, dim=1)  # Normalize embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9619723-25a6-49e5-ab88-42fea483e730",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7967babf6ca04561891f943c9dd2945d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\miniforge3\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\steph\\.cache\\huggingface\\hub\\models--sentence-transformers--distiluse-base-multilingual-cased-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1867\n",
      "Epoch 2, Loss: 0.1280\n",
      "Epoch 3, Loss: 0.1028\n",
      "Epoch 4, Loss: 0.0711\n",
      "Epoch 5, Loss: 0.0523\n",
      "Epoch 6, Loss: 0.0305\n",
      "Epoch 7, Loss: 0.0162\n",
      "Epoch 8, Loss: 0.0096\n",
      "Epoch 9, Loss: 0.0067\n",
      "Epoch 10, Loss: 0.0051\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = PaperRecommender().to(\"cuda\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "def contrastive_loss(embeddings):\n",
    "    \"\"\"Loss function using pairwise Euclidean distances in the batch.\"\"\"\n",
    "    # Normalize embeddings (optional, helps numerical stability)\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)  \n",
    "    # Compute pairwise Euclidean distances\n",
    "    distance_matrix = torch.cdist(embeddings, embeddings, p=2)  # (batch_size, batch_size)\n",
    "    # Minimize the sum of all distances (encourages compact embedding space)\n",
    "    loss = distance_matrix.sum() / (embeddings.shape[0] ** 2)  # Normalize by batch_size^2\n",
    "    return loss\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(input_ids, attention_mask)  # Shape: (batch_size, embedding_dim)\n",
    "\n",
    "        # Compute loss using pairwise distances between all embeddings\n",
    "        loss = contrastive_loss(embeddings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b1bddb-dea3-4a5d-9e80-3da76064b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_papers(query, model, df, top_k=5):\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize and encode query\n",
    "    query_tokens = tokenizer(query, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        query_embedding = model(query_tokens[\"input_ids\"], query_tokens[\"attention_mask\"]).cpu().numpy()\n",
    "\n",
    "    # Compute Euclidean distances between query and all paper embeddings\n",
    "    paper_embeddings = []\n",
    "    paper_indices = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch_input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        batch_attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch_input_ids, batch_attention_mask).cpu().numpy()\n",
    "            paper_embeddings.append(batch_embeddings)\n",
    "            paper_indices.extend(batch[\"paper_index\"].numpy())  # Store original indices\n",
    "\n",
    "    paper_embeddings = np.vstack(paper_embeddings)  # Stack all embeddings\n",
    "    paper_indices = np.array(paper_indices)\n",
    "\n",
    "    # Compute pairwise Euclidean distances\n",
    "    distances = np.linalg.norm(paper_embeddings - query_embedding, axis=1)\n",
    "\n",
    "    # Get top-k closest papers (smallest distances)\n",
    "    top_indices = np.argsort(distances)[:top_k]\n",
    "\n",
    "    print(\"\\nRecommended Papers:\")\n",
    "    for idx in top_indices:\n",
    "        paper_idx = paper_indices[idx]\n",
    "        print(f\"Title: {df.iloc[paper_idx]['title']}\\nAbstract: {df.iloc[paper_idx]['abstract']}\\nDistance: {distances[idx]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a25f812-4c97-4260-a369-d4a766f40744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended Papers:\n",
      "Title: Analysis of EV Charging Coordination Efficiency in Presence of Cheating Customers\n",
      "Abstract: Charging coordination is employed to efficiently serve electric vehicle (EV) charging requests without overloading the distribution network. Parameters such as parking duration, battery state-of-charge (SoC), and charging amount are provided by EVs to the charging coordination center to schedule their charging requests efficiently. The existing literature assumes that the customers always provide correct information. Unfortunately, customers may provide false information to gain higher charging priority. Assessing the impact of cheating behavior represents a significant and open problem. Herein paper, the impact of providing false information (e.g., parking duration) on the efficiency of the charging coordination mechanism is investigated. The charging coordination strategy is formulated as a linear optimization problem. Two different objectives are used to assess the impact of the objective function on the amount of performance degradation. Our investigations reveal that the degradation of the efficiency of the charging coordination mechanism depends on the percentage of cheating customers and cheating duration versus the typical parking duration. In addition, the impact of cheating behavior increases with the number of deployed chargers. Thus, the severity of the cheating impact will increase in the future as more fast chargers are allocated in charging networks.\n",
      "Distance: 0.1544\n",
      "\n",
      "Title: Magnetic Field and Temperature Dual-Parameter Sensor Based on Nonadiabatic Tapered Microfiber Cascaded With FBG\n",
      "Abstract: A kind of dual-parameter sensor based on magnetic-fluid-coated nonadiabatic tapered microfiber (NTF) cascaded with fiber Bragg grating (FBG) is proposed and experimentally demonstrated. Simultaneous measurement of magnetic field and temperature is realized by monitoring the variation of NTF interference spectrum and FBG characteristic dip. In the magnetic field range of 0–18 mT, the highest magnetic field sensitivity can reach 1.159 nm/mT. The maximum temperature sensitivity is up to −1.737 nm/°C in the temperature range of 25-50 °C. The proposed magnetic-fluid-coated NTF interferometer cascaded with FBG will find extensive application prospect due to its high sensitivity, easy fabrication, compactness, strong robustness, and low cost.\n",
      "Distance: 0.1558\n",
      "\n",
      "Title: Hybrid Stochastic Ranking for Constrained Optimization\n",
      "Abstract: Teaching learning based optimization (TLBO) algorithm is a distinguished nature-inspired population-based meta-heuristic, which is basically designed for unconstrained optimization. TLBO mimics teaching learning process through which learners acquire knowledge from their teachers, and improve their results/grades, accordingly. Stochastic ranking (SR) is a constrained handling technique (CHT), which produces greediness among solutions to improve their fitness values and feasibility. Violation constraint handling (VCH) technique produces more feasibility among the existing superiority of feasibility CHTs due to its additional factor of ranking based on the number of constraints violated (NCV). This work brings in a new variant of SR, namely hybrid stochastic ranking (HSR), which combines SR and VCH. For constrained optimization, the integration of some CHT with TLBO is essential. In this paper, HSR is integrated with TLBO and a new constrained version of TLBO called HSR-TLBO is designed. The efficiency of HSR-TLBO is checked on constrained test functions of the suit CEC 2017. The experimental results show that HSR-TLBO got prominent position when compared and ranked with the top four papers and our two newly designed constrained variants of TLBO, MSR-TLBO and MVCH-TLBO, based on the provided budget and ranking criteria of the mentioned suit.\n",
      "Distance: 0.1559\n",
      "\n",
      "Title: A Novel Array Configuration Technique for Improving the Power Output of the Partial Shaded Photovoltaic System\n",
      "Abstract: Power conversion efficiency is the most important factor to be considered in PV systems because it is affected by various environmental conditions. The effect of partial shading is the most influenced factor in the reduction of power output. Various research schemes like Maximum Power Point Tracking (MPPT), array configuration scheme, reconfiguration, etc., work on the PV system to reduce the impact of partial shading. This paper presents a new kind of array configuration scheme that forms the PV array based on the moves of the Knight coin in the chess game. This arrangement creates the squared PV array of rows with distinct PV modules which is capable of evenly dispersing the shading in the partially shaded PV array. Also, this scheme is applicable for the non-squared PV arrays to create PV rows with the PV modules from a distinct location or from the same row with optimized distance to disperse the maximum level of shading. The proposed method has been discussed with the proper mathematical formulation with all necessary constraints and also it been validated with the hardware arrangements and MATLAB/Simulink\n",
      "®\n",
      " model.\n",
      "Distance: 0.1560\n",
      "\n",
      "Title: Improving IoT Federation Resiliency With Distributed Ledger Technology\n",
      "Abstract: Despite the rapid spread of Internet of Things (IoT) systems, the lack of interoperability between the systems significantly hinders their business and societal potential. Moreover, a major challenge for wider interoperability is that the IoT systems can be owned by multiple independent entities, whose collaboration will need to be organised to ensure their interoperability. One approach for achieving this is to establish federations supported by Distributed Ledger Technologies (DLTs), as this enables interoperability between entities and collaboration between business platforms, thereby overcoming many technical and administrative difficulties. DLTs can provide the required transparency and immutability for management of the federations, thus increasing trust and reducing the risk of misbehaviour that could destabilise the federation. This paper presents two system dynamics simulation models, which demonstrate that the success of a federation (with or without DLT support) is inversely related to the short-term selfishness of its members, and we then proceed to show that DLTs can improve the feedback received by the federation members on their actions by promoting a common consensus, which in turn can make the federation more resilient.\n",
      "Distance: 0.1561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommend_papers(\"deep learning for edge computing\", model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd8b34-d743-441f-8b39-6b8162e06224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
