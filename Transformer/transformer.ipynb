{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d664a8f3-deb0-47ee-96dd-4a094ba076f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\steph\\miniforge3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60393e37-8f4c-4abc-866f-024d0d1d697c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (385, 8), Validation: (110, 8), Test: (56, 8)\n"
     ]
    }
   ],
   "source": [
    "# train 70%, val 20%, test 10%\n",
    "df = pd.read_csv(\"database_clean.csv\")\n",
    "df = df.dropna(subset=['title', 'abstract'])\n",
    "#df = df.head(400)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, X_temp = train_test_split(df, test_size=0.3, random_state=42)\n",
    "X_val, X_test = train_test_split(X_temp, test_size=1/3, random_state=42)\n",
    "print(f\"Train: {X_train.shape}, Validation: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0718d3bf-0782-450d-8a8b-ef1130b0bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/distiluse-base-multilingual-cased-v1\")\n",
    "\n",
    "class PaperDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title = str(self.data.iloc[idx][\"title\"])\n",
    "        abstract = str(self.data.iloc[idx][\"abstract\"])\n",
    "        input_text = title + \" \" + abstract  # Combine title and abstract\n",
    "        \n",
    "        tokens = self.tokenizer(\n",
    "            input_text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": tokens[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": tokens[\"attention_mask\"].squeeze(0),\n",
    "            \"paper_index\": idx  # Used for retrieval\n",
    "        }\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "dataset_train = PaperDataset(X_train, tokenizer, 256)\n",
    "dataset_val = PaperDataset(X_val, tokenizer, 256)\n",
    "dataloader = DataLoader(dataset_train, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f242b441-9990-4523-92cc-243e5fa7facb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Input IDs Shape: torch.Size([8, 256])\n",
      "Batch Attention Mask Shape: torch.Size([8, 256])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(\"Batch Input IDs Shape:\", batch[\"input_ids\"].shape)\n",
    "    print(\"Batch Attention Mask Shape:\", batch[\"attention_mask\"].shape)\n",
    "    break  # Check only the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50964c3e-9433-4a3a-8fa7-40b5575ca93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperRecommender(nn.Module):\n",
    "    def __init__(self, model_name, embedding_dim, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.embedding_dim = embedding_dim  # Ensure this is correctly set\n",
    "\n",
    "        # Ensure projection layer matches `embedding_dim`\n",
    "        self.fc = nn.Linear(self.encoder.config.hidden_size, embedding_dim)  \n",
    "        \n",
    "        # Multiheaded attention layer using the correct `embedding_dim`\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads, dropout=dropout)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.normalize = nn.functional.normalize\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        input_ids = input_ids.to(next(self.parameters()).device)\n",
    "        attention_mask = attention_mask.to(next(self.parameters()).device)\n",
    "\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # CLS token representation\n",
    "\n",
    "        embedding = self.fc(self.dropout(pooled_output))  # Apply projection\n",
    "        embedding = embedding.unsqueeze(0)  # Reshape for MultiheadAttention\n",
    "\n",
    "        # Multiheaded Attention\n",
    "        attn_output, _ = self.attention(embedding, embedding, embedding)\n",
    "        attn_output = attn_output.squeeze(0)  # Remove batch dim\n",
    "\n",
    "        return self.normalize(attn_output, p=2, dim=1)  # Normalize embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3558e342-5329-4e21-b2fd-36a7a60540dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0750, 0.0598,  ..., 0.0521, 0.0948, 0.0936],\n",
      "        [0.0750, 1.0000, 0.0727,  ..., 0.0725, 0.0826, 0.0915],\n",
      "        [0.0598, 0.0727, 1.0000,  ..., 0.0706, 0.0856, 0.0740],\n",
      "        ...,\n",
      "        [0.0521, 0.0725, 0.0706,  ..., 1.0000, 0.0538, 0.0668],\n",
      "        [0.0948, 0.0826, 0.0856,  ..., 0.0538, 1.0000, 0.1076],\n",
      "        [0.0936, 0.0915, 0.0740,  ..., 0.0668, 0.1076, 1.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([[ True, False, False,  ..., False,  True,  True],\n",
      "        [False,  True, False,  ..., False,  True,  True],\n",
      "        [False, False,  True,  ..., False,  True, False],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True, False, False],\n",
      "        [ True,  True,  True,  ..., False,  True,  True],\n",
      "        [ True,  True, False,  ..., False,  True,  True]], device='cuda:0')\n",
      "tensor([[False,  True,  True,  ...,  True, False, False],\n",
      "        [ True, False,  True,  ...,  True, False, False],\n",
      "        [ True,  True, False,  ...,  True, False,  True],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False,  True,  True],\n",
      "        [False, False, False,  ...,  True, False, False],\n",
      "        [False, False,  True,  ...,  True, False, False]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def compute_tfidf_similarity(df):\n",
    "    corpus = df['title'] + \" \" + df['abstract']\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    return similarity_matrix\n",
    "\n",
    "similarity_matrix_np = compute_tfidf_similarity(df)\n",
    "# Convert to tensor for GPU computation\n",
    "similarity_matrix = torch.tensor(similarity_matrix_np, dtype=torch.float32).to(\"cuda\")\n",
    "print(similarity_matrix)\n",
    "\n",
    "threshold = 0.0785\n",
    "\n",
    "positive_pairs = similarity_matrix > threshold\n",
    "negative_pairs = ~positive_pairs\n",
    "print(positive_pairs)\n",
    "print(negative_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65b2aaef-c81f-4998-9ac3-44d3d2904eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85th percentile: 0.1105\n",
      "90th percentile: 0.1205\n",
      "95th percentile: 0.1374\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "#Organize Data\n",
    "similarity_values_np = similarity_matrix_np.flatten()\n",
    "similarity_values_np_filtered = similarity_values_np[similarity_values_np <= 0.25]\n",
    "X = pd.Series(similarity_values_np_filtered, name=\"(Similarity Matrix Distribution)\")\n",
    "\n",
    "#Plot Data\n",
    "fig, ax = plt.subplots()\n",
    "sns.histplot(X, bins=25, color=\"g\", ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# Compute percentiles\n",
    "percentiles = [85, 90, 95]\n",
    "percentile_values = np.percentile(similarity_values_np_filtered, percentiles)\n",
    "\n",
    "# Print results\n",
    "for p, val in zip(percentiles, percentile_values):\n",
    "    print(f\"{p}th percentile: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adb2e70a-fe2c-4669-ad62-8c38b01505f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch, loss, path=\"./paper_recommender.pth\"):\n",
    "    \"\"\"Save the model, optimizer state, and training metadata.\"\"\"\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"loss\": loss\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Model saved at {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fa12bbd-aa94-4282-b3e9-4bafbbf51259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, optimizer=None, path = \"./paper_recommender.pth\"):\n",
    "    \"\"\"Load the model and optionally the optimizer.\"\"\"\n",
    "    checkpoint = torch.load(path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    print(f\"Model loaded from {path}, trained until epoch {checkpoint['epoch']}\")\n",
    "    \n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        print(\"Optimizer state restored.\")\n",
    "\n",
    "    return checkpoint[\"epoch\"], checkpoint[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc03d8a2-8a92-4a9b-8b63-b2549cc36377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(embeddings, similarity_matrix, indices, margin=0.5):\n",
    "    \"\"\"\n",
    "    Contrastive loss using TF-IDF similarity as ground truth.\n",
    "    \n",
    "    embeddings: (batch_size, embedding_dim)\n",
    "    similarity_matrix: Precomputed TF-IDF cosine similarity.\n",
    "    indices: Indices of batch samples in dataset.\n",
    "    margin: Margin for contrastive loss.\n",
    "    \"\"\"\n",
    "    batch_size = embeddings.shape[0]\n",
    "\n",
    "    # Ensure embeddings are L2 normalized\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = torch.mm(embeddings, embeddings.T)  # (batch_size, batch_size)\n",
    "    cosine_distances = 1 - cosine_sim  # Convert similarity to distance\n",
    "\n",
    "    # Extract ground truth similarity values for batch samples\n",
    "    ground_truth_similarities = similarity_matrix[indices][:, indices]\n",
    "\n",
    "    # Define positive and negative pairs\n",
    "    threshold = 0.1205  # Adjust this value if needed\n",
    "    positive_pairs = (ground_truth_similarities > threshold).float()\n",
    "    negative_pairs = (ground_truth_similarities <= threshold).float()\n",
    "\n",
    "    # Compute losses\n",
    "    positive_loss = (cosine_distances * positive_pairs).sum() / (positive_pairs.sum() + 1e-8)\n",
    "    negative_loss = torch.clamp(margin - cosine_distances, min=0) * negative_pairs\n",
    "    negative_loss = negative_loss.sum() / (negative_pairs.sum() + 1e-8)\n",
    "\n",
    "    loss = positive_loss + negative_loss\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea65a89c-88ae-45e3-b7e1-957058b21736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameter search space\n",
    "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [256, 512, 768])\n",
    "    num_heads = trial.suggest_categorical(\"num_heads\", [2,4,8,16])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.3)\n",
    "\n",
    "    # Initialize model with selected hyperparameters\n",
    "    model = PaperRecommender(\"sentence-transformers/distiluse-base-multilingual-cased-v1\",\n",
    "                             embedding_dim, num_heads, dropout).to(\"cuda\")\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    # Create train and validation dataloaders\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=8, shuffle=True)\n",
    "    dataloader_val = DataLoader(dataset_val, batch_size=8, shuffle=False)\n",
    "\n",
    "    num_epochs = 3  # Use fewer epochs for tuning\n",
    "    total_loss = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in dataloader_train:\n",
    "            input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "            attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "            indices = batch[\"paper_index\"].cpu().numpy()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            embeddings = model(input_ids, attention_mask)\n",
    "\n",
    "            loss = contrastive_loss(embeddings, similarity_matrix, indices, margin=0.5)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = epoch_loss / len(dataloader_train)\n",
    "\n",
    "        # Validation step (compute loss on validation set)\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader_val:\n",
    "                input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "                attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "                indices = batch[\"paper_index\"].cpu().numpy()\n",
    "\n",
    "                embeddings = model(input_ids, attention_mask)\n",
    "                val_loss += contrastive_loss(embeddings, similarity_matrix, indices, margin=0.5).item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(dataloader_val)\n",
    "        total_loss += avg_val_loss\n",
    "\n",
    "    return total_loss / num_epochs  # Minimize validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a1396d4-1570-443a-93d7-8ffc52a66caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-08 09:46:37,166] A new study created in memory with name: no-name-22ef04b7-4c24-47e7-9483-87543b3ef608\n",
      "[I 2025-03-08 09:56:38,653] Trial 0 finished with value: 0.25676934261407175 and parameters: {'embedding_dim': 256, 'num_heads': 16, 'dropout': 0.13280174353480928}. Best is trial 0 with value: 0.25676934261407175.\n",
      "[I 2025-03-08 10:06:40,938] Trial 1 finished with value: 0.23731256436024395 and parameters: {'embedding_dim': 768, 'num_heads': 8, 'dropout': 0.11071900448610628}. Best is trial 1 with value: 0.23731256436024395.\n",
      "[I 2025-03-08 10:16:36,669] Trial 2 finished with value: 0.2542575315705367 and parameters: {'embedding_dim': 256, 'num_heads': 8, 'dropout': 0.11045636255786613}. Best is trial 1 with value: 0.23731256436024395.\n",
      "[I 2025-03-08 10:26:31,902] Trial 3 finished with value: 0.295942437790689 and parameters: {'embedding_dim': 512, 'num_heads': 4, 'dropout': 0.2181322300274679}. Best is trial 1 with value: 0.23731256436024395.\n",
      "[I 2025-03-08 10:36:28,147] Trial 4 finished with value: 0.2953420817142441 and parameters: {'embedding_dim': 768, 'num_heads': 4, 'dropout': 0.23983028030632095}. Best is trial 1 with value: 0.23731256436024395.\n",
      "[I 2025-03-08 10:46:27,838] Trial 5 finished with value: 0.27226502749891507 and parameters: {'embedding_dim': 256, 'num_heads': 2, 'dropout': 0.14947370221787312}. Best is trial 1 with value: 0.23731256436024395.\n",
      "[I 2025-03-08 10:56:26,659] Trial 6 finished with value: 0.29827602207660675 and parameters: {'embedding_dim': 256, 'num_heads': 16, 'dropout': 0.18086788842155738}. Best is trial 1 with value: 0.23731256436024395.\n",
      "[W 2025-03-08 11:01:36,295] Trial 7 failed with parameters: {'embedding_dim': 768, 'num_heads': 16, 'dropout': 0.20321117235627667} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\steph\\miniforge3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\steph\\AppData\\Local\\Temp\\ipykernel_17168\\1336417907.py\", line 31, in objective\n",
      "    loss = contrastive_loss(embeddings, similarity_matrix, indices, margin=0.5)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\steph\\AppData\\Local\\Temp\\ipykernel_17168\\2096215491.py\", line 24, in contrastive_loss\n",
      "    positive_pairs = (ground_truth_similarities > threshold).float()\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-03-08 11:01:36,297] Trial 7 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# We want to minimize loss\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Run 20 trials\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[1;32m~\\miniforge3\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\miniforge3\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\miniforge3\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\miniforge3\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[37], line 31\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     29\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask)\n\u001b[1;32m---> 31\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcontrastive_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmargin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[36], line 24\u001b[0m, in \u001b[0;36mcontrastive_loss\u001b[1;34m(embeddings, similarity_matrix, indices, margin)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Define positive and negative pairs\u001b[39;00m\n\u001b[0;32m     23\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1205\u001b[39m  \u001b[38;5;66;03m# Adjust this value if needed\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m positive_pairs \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mground_truth_similarities\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m negative_pairs \u001b[38;5;241m=\u001b[39m (ground_truth_similarities \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Compute losses\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")  # We want to minimize loss\n",
    "study.optimize(objective, n_trials=20)  # Run 20 trials\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9619723-25a6-49e5-ab88-42fea483e730",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = PaperRecommender(\"sentence-transformers/distiluse-base-multilingual-cased-v1\",\n",
    "                               best_params[\"embedding_dim\"],\n",
    "                               best_params[\"num_heads\"],\n",
    "                               best_params[\"dropout\"]).to(\"cuda\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "        indices = batch[\"paper_index\"].cpu().numpy()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(input_ids, attention_mask)\n",
    "\n",
    "        loss = contrastive_loss(embeddings, similarity_matrix, indices, margin=0.5)\n",
    "\n",
    "        if loss.item() == 0:\n",
    "            print(f\"Warning: Zero loss at epoch {epoch+1}. Debug required.\")\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Avg Loss: {avg_loss:.4f}\")\n",
    "    save_model(model, optimizer, epoch + 1, avg_loss, \"paper_recommender.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34304d1d-4b28-47f7-b4c2-f16cf607b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = PaperRecommender().to(\"cuda\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Load the model (after training)\n",
    "epoch, loss = load_model(model, optimizer, \"paper_recommender.pth\")\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1bddb-dea3-4a5d-9e80-3da76064b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_papers(query, model, df, top_k=5):\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize and encode query\n",
    "    query_tokens = tokenizer(query, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        query_embedding = model(query_tokens[\"input_ids\"], query_tokens[\"attention_mask\"]).cpu().numpy()\n",
    "\n",
    "    # Compute Euclidean distances between query and all paper embeddings\n",
    "    paper_embeddings = []\n",
    "    paper_indices = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch_input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        batch_attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch_input_ids, batch_attention_mask).cpu().numpy()\n",
    "            paper_embeddings.append(batch_embeddings)\n",
    "            paper_indices.extend(batch[\"paper_index\"].numpy())  # Store original indices\n",
    "\n",
    "    paper_embeddings = np.vstack(paper_embeddings)  # Stack all embeddings\n",
    "    paper_indices = np.array(paper_indices)\n",
    "\n",
    "    # Compute pairwise Euclidean distances\n",
    "    distances = np.linalg.norm(paper_embeddings - query_embedding, axis=1)\n",
    "\n",
    "    # Get top-k closest papers (smallest distances)\n",
    "    top_indices = np.argsort(distances)[:top_k]\n",
    "\n",
    "    print(\"\\nRecommended Papers:\")\n",
    "    for idx in top_indices:\n",
    "        paper_idx = paper_indices[idx]\n",
    "        print(f\"Title: {df.iloc[paper_idx]['title']}\\nAbstract: {df.iloc[paper_idx]['abstract']}\\nDistance: {distances[idx]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a25f812-4c97-4260-a369-d4a766f40744",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_papers(\"deep learning for edge computing\", model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd8b34-d743-441f-8b39-6b8162e06224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all papers using the trained model\n",
    "def get_embeddings(dataloader, model):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    paper_indices = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "            attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "            batch_embeddings = model(input_ids, attention_mask)  # Keep as CUDA tensor\n",
    "            embeddings.append(batch_embeddings)  # Store without converting to NumPy\n",
    "            paper_indices.extend(batch[\"paper_index\"].numpy())\n",
    "\n",
    "    return torch.cat(embeddings, dim=0), np.array(paper_indices)  # Return PyTorch tensor\n",
    "\n",
    "# Get embeddings for train and test sets\n",
    "train_dataloader = DataLoader(PaperDataset(X_train, tokenizer, 256), batch_size=8, shuffle=False)\n",
    "test_dataloader = DataLoader(PaperDataset(X_test, tokenizer, 256), batch_size=8, shuffle=False)\n",
    "\n",
    "train_embeddings, train_indices = get_embeddings(train_dataloader, model)\n",
    "test_embeddings, test_indices = get_embeddings(test_dataloader, model)\n",
    "\n",
    "# Compute cosine similarity in CUDA\n",
    "train_embeddings = F.normalize(train_embeddings, p=2, dim=1)  # Normalize embeddings\n",
    "test_embeddings = F.normalize(test_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sample Test Embedding:\", test_embeddings[0][:15])  # First 15 values\n",
    "print(\"Sample Train Embedding:\", train_embeddings[0][:15])  # First 15 values\n",
    "\n",
    "similarity_matrix = torch.matmul(test_embeddings, train_embeddings.T).cpu().numpy()  # Cosine similarity\n",
    "\n",
    "# Select top-N most similar papers\n",
    "top_n = 10\n",
    "top_indices = np.argsort(-similarity_matrix, axis=1)[:, :top_n]\n",
    "\n",
    "# Print recommended papers\n",
    "recommended_paper_ids = []\n",
    "\n",
    "for i, test_idx in enumerate(top_indices):\n",
    "    recommended_for_test = []\n",
    "    print(f\"\\nTest Paper {i+1}:\")\n",
    "    \n",
    "    for j, train_idx in enumerate(test_idx):\n",
    "        recommended_paper_id = X_train.iloc[train_indices[train_idx]][\"Id\"]\n",
    "        recommended_for_test.append(recommended_paper_id)\n",
    "        \n",
    "        print(f\"  {j+1}. Recommended Paper ID: {recommended_paper_id} (Similarity: {similarity_matrix[i, train_idx]:.4f})\")\n",
    "    \n",
    "    recommended_paper_ids.append(recommended_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af7a75-f560-4fce-84d8-c483c7855b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
