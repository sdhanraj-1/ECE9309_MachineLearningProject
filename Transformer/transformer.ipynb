{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d664a8f3-deb0-47ee-96dd-4a094ba076f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\steph\\miniforge3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60393e37-8f4c-4abc-866f-024d0d1d697c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (385, 8), Validation: (110, 8), Test: (56, 8)\n"
     ]
    }
   ],
   "source": [
    "# train 70%, val 20%, test 10%\n",
    "df = pd.read_csv(\"database_clean.csv\")\n",
    "df = df.dropna(subset=['title', 'abstract'])\n",
    "#df = df.head(400)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, X_temp = train_test_split(df, test_size=0.3, random_state=42)\n",
    "X_val, X_test = train_test_split(X_temp, test_size=1/3, random_state=42)\n",
    "print(f\"Train: {X_train.shape}, Validation: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0718d3bf-0782-450d-8a8b-ef1130b0bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/distiluse-base-multilingual-cased-v1\")\n",
    "\n",
    "class PaperDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title = str(self.data.iloc[idx][\"title\"])\n",
    "        abstract = str(self.data.iloc[idx][\"abstract\"])\n",
    "        input_text = title + \" \" + abstract  # Combine title and abstract\n",
    "        \n",
    "        tokens = self.tokenizer(\n",
    "            input_text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": tokens[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": tokens[\"attention_mask\"].squeeze(0),\n",
    "            \"paper_index\": idx  # Used for retrieval\n",
    "        }\n",
    "\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "dataset_train = PaperDataset(X_train, tokenizer, 256)\n",
    "dataloader = DataLoader(dataset_train, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f242b441-9990-4523-92cc-243e5fa7facb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Input IDs Shape: torch.Size([8, 256])\n",
      "Batch Attention Mask Shape: torch.Size([8, 256])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(\"Batch Input IDs Shape:\", batch[\"input_ids\"].shape)\n",
    "    print(\"Batch Attention Mask Shape:\", batch[\"attention_mask\"].shape)\n",
    "    break  # Check only the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50964c3e-9433-4a3a-8fa7-40b5575ca93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperRecommender(nn.Module):\n",
    "    def __init__(self, model_name=\"sentence-transformers/distiluse-base-multilingual-cased-v1\", embedding_dim=768, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.fc = nn.Linear(self.embedding_dim, embedding_dim)  # Projection layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.normalize = nn.functional.normalize  # L2 normalization for retrieval\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        input_ids = input_ids.to(next(self.parameters()).device)  # Ensure inputs are on the same device as the model\n",
    "        attention_mask = attention_mask.to(next(self.parameters()).device)\n",
    "        \n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # CLS token representation\n",
    "        embedding = self.fc(self.dropout(pooled_output))\n",
    "        return self.normalize(embedding, p=2, dim=1)  # Normalize embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3558e342-5329-4e21-b2fd-36a7a60540dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0750, 0.0598,  ..., 0.0521, 0.0948, 0.0936],\n",
      "        [0.0750, 1.0000, 0.0727,  ..., 0.0725, 0.0826, 0.0915],\n",
      "        [0.0598, 0.0727, 1.0000,  ..., 0.0706, 0.0856, 0.0740],\n",
      "        ...,\n",
      "        [0.0521, 0.0725, 0.0706,  ..., 1.0000, 0.0538, 0.0668],\n",
      "        [0.0948, 0.0826, 0.0856,  ..., 0.0538, 1.0000, 0.1076],\n",
      "        [0.0936, 0.0915, 0.0740,  ..., 0.0668, 0.1076, 1.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([[ True, False, False,  ..., False,  True,  True],\n",
      "        [False,  True, False,  ..., False,  True,  True],\n",
      "        [False, False,  True,  ..., False,  True, False],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True, False, False],\n",
      "        [ True,  True,  True,  ..., False,  True,  True],\n",
      "        [ True,  True, False,  ..., False,  True,  True]], device='cuda:0')\n",
      "tensor([[False,  True,  True,  ...,  True, False, False],\n",
      "        [ True, False,  True,  ...,  True, False, False],\n",
      "        [ True,  True, False,  ...,  True, False,  True],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False,  True,  True],\n",
      "        [False, False, False,  ...,  True, False, False],\n",
      "        [False, False,  True,  ...,  True, False, False]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def compute_tfidf_similarity(df):\n",
    "    corpus = df['title'] + \" \" + df['abstract']\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    return similarity_matrix\n",
    "\n",
    "similarity_matrix = compute_tfidf_similarity(df)\n",
    "# Convert to tensor for GPU computation\n",
    "similarity_matrix = torch.tensor(similarity_matrix, dtype=torch.float32).to(\"cuda\")\n",
    "print(similarity_matrix)\n",
    "\n",
    "threshold = 0.0785\n",
    "\n",
    "positive_pairs = similarity_matrix > threshold\n",
    "negative_pairs = ~positive_pairs\n",
    "print(positive_pairs)\n",
    "print(negative_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb2e70a-fe2c-4669-ad62-8c38b01505f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch, loss, path=\"./paper_recommender.pth\"):\n",
    "    \"\"\"Save the model, optimizer state, and training metadata.\"\"\"\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"loss\": loss\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Model saved at {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fa12bbd-aa94-4282-b3e9-4bafbbf51259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, optimizer=None, path = \"./paper_recommender.pth\"):\n",
    "    \"\"\"Load the model and optionally the optimizer.\"\"\"\n",
    "    checkpoint = torch.load(path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    print(f\"Model loaded from {path}, trained until epoch {checkpoint['epoch']}\")\n",
    "    \n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        print(\"Optimizer state restored.\")\n",
    "\n",
    "    return checkpoint[\"epoch\"], checkpoint[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9619723-25a6-49e5-ab88-42fea483e730",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 0.3906\n",
      "Model saved at ./paper_recommender.pth\n",
      "Epoch 2, Avg Loss: 0.3675\n",
      "Model saved at ./paper_recommender.pth\n",
      "Warning: Zero loss at epoch 3. Debug required.\n",
      "Epoch 3, Avg Loss: 0.3584\n",
      "Model saved at ./paper_recommender.pth\n",
      "Warning: Zero loss at epoch 4. Debug required.\n",
      "Epoch 4, Avg Loss: 0.3448\n",
      "Model saved at ./paper_recommender.pth\n",
      "Warning: Zero loss at epoch 5. Debug required.\n",
      "Epoch 5, Avg Loss: 0.3348\n",
      "Model saved at ./paper_recommender.pth\n",
      "Epoch 6, Avg Loss: 0.3095\n",
      "Model saved at ./paper_recommender.pth\n",
      "Epoch 7, Avg Loss: 0.3035\n",
      "Model saved at ./paper_recommender.pth\n",
      "Warning: Zero loss at epoch 8. Debug required.\n",
      "Epoch 8, Avg Loss: 0.3017\n",
      "Model saved at ./paper_recommender.pth\n",
      "Epoch 9, Avg Loss: 0.2792\n",
      "Model saved at ./paper_recommender.pth\n",
      "Epoch 10, Avg Loss: 0.2679\n",
      "Model saved at ./paper_recommender.pth\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = PaperRecommender().to(\"cuda\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "def contrastive_loss(embeddings, similarity_matrix, indices, margin=0.5):\n",
    "    \"\"\"\n",
    "    Contrastive loss using TF-IDF similarity as ground truth.\n",
    "    \n",
    "    embeddings: (batch_size, embedding_dim)\n",
    "    similarity_matrix: Precomputed TF-IDF cosine similarity.\n",
    "    indices: Indices of batch samples in dataset.\n",
    "    margin: Margin for contrastive loss.\n",
    "    \"\"\"\n",
    "    batch_size = embeddings.shape[0]\n",
    "\n",
    "    # Ensure embeddings are L2 normalized\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = torch.mm(embeddings, embeddings.T)  # (batch_size, batch_size)\n",
    "    cosine_distances = 1 - cosine_sim  # Convert similarity to distance\n",
    "\n",
    "    # Extract ground truth similarity values for batch samples\n",
    "    ground_truth_similarities = similarity_matrix[indices][:, indices]\n",
    "\n",
    "    # Define positive and negative pairs\n",
    "    threshold = 0.0785  # Adjust this value if needed\n",
    "    positive_pairs = (ground_truth_similarities > threshold).float()\n",
    "    negative_pairs = (ground_truth_similarities <= threshold).float()\n",
    "\n",
    "    # Compute losses\n",
    "    positive_loss = (cosine_distances * positive_pairs).sum() / (positive_pairs.sum() + 1e-8)\n",
    "    negative_loss = torch.clamp(margin - cosine_distances, min=0) * negative_pairs\n",
    "    negative_loss = negative_loss.sum() / (negative_pairs.sum() + 1e-8)\n",
    "\n",
    "    loss = positive_loss + negative_loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "        indices = batch[\"paper_index\"].cpu().numpy()  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(input_ids, attention_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = contrastive_loss(embeddings, similarity_matrix, indices, margin=0.5)\n",
    "        \n",
    "        if loss.item() == 0:\n",
    "            print(f\"Warning: Zero loss at epoch {epoch+1}. Debug required.\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Avg Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "    # Save model after each epoch\n",
    "    save_path = \"./paper_recommender.pth\"\n",
    "    save_model(model, optimizer, epoch + 1, avg_loss, save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34304d1d-4b28-47f7-b4c2-f16cf607b4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from paper_recommender.pth, trained until epoch 10\n",
      "Optimizer state restored.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PaperRecommender(\n",
       "  (encoder): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = PaperRecommender().to(\"cuda\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Load the model (after training)\n",
    "epoch, loss = load_model(model, optimizer, \"paper_recommender.pth\")\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b1bddb-dea3-4a5d-9e80-3da76064b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_papers(query, model, df, top_k=5):\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize and encode query\n",
    "    query_tokens = tokenizer(query, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        query_embedding = model(query_tokens[\"input_ids\"], query_tokens[\"attention_mask\"]).cpu().numpy()\n",
    "\n",
    "    # Compute Euclidean distances between query and all paper embeddings\n",
    "    paper_embeddings = []\n",
    "    paper_indices = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch_input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        batch_attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch_input_ids, batch_attention_mask).cpu().numpy()\n",
    "            paper_embeddings.append(batch_embeddings)\n",
    "            paper_indices.extend(batch[\"paper_index\"].numpy())  # Store original indices\n",
    "\n",
    "    paper_embeddings = np.vstack(paper_embeddings)  # Stack all embeddings\n",
    "    paper_indices = np.array(paper_indices)\n",
    "\n",
    "    # Compute pairwise Euclidean distances\n",
    "    distances = np.linalg.norm(paper_embeddings - query_embedding, axis=1)\n",
    "\n",
    "    # Get top-k closest papers (smallest distances)\n",
    "    top_indices = np.argsort(distances)[:top_k]\n",
    "\n",
    "    print(\"\\nRecommended Papers:\")\n",
    "    for idx in top_indices:\n",
    "        paper_idx = paper_indices[idx]\n",
    "        print(f\"Title: {df.iloc[paper_idx]['title']}\\nAbstract: {df.iloc[paper_idx]['abstract']}\\nDistance: {distances[idx]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a25f812-4c97-4260-a369-d4a766f40744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended Papers:\n",
      "Title: DFT Spread-Optical Pulse Amplitude Modulation for Visible Light Communication Systems\n",
      "Abstract: DC-biased optical orthogonal frequency division multiplexing (DCO-OFDM) has been proposed in visible light communication (VLC) to overcome the limited modulation bandwidth of light emitting diode (LED). Due to the implementation of the inverse fast Fourier transform at the DCO-OFDM transmitter, DCO-OFDM suffers from its high peak-to-average power ratio (PAPR), which restricts its use in some VLC applications, especially where the optical power efficiency is a crucial requirement. That is because the LEDs used in VLC systems have a limited optical power-current linear range. To this end, a novel discrete Fourier transform spread-optical pulse amplitude modulation (DFTS-OPAM) signal scheme based on the single carrier-interleaved frequency division multiple access (SC-IFDMA) signal is introduced in this paper to address the high PAPR issue of OFDM. DFTS-OPAM is achieved by considering a PAM as an SC-IFDMA data symbol and duplicate the output vector of the fast Fourier transform at the SC-IFDMA transmitter side. Simulation results show that the PAPR of the proposed scheme is 7 dB lower than that of DCO-OFDM. Furthermore, this significant PAPR improvement is experimentally investigated where the practical results show that the proposed scheme can provide more 2.5 dB reduction in the average transmitted power requirement compared to DCO-OFDM and can subsequently increase the maximum achieved distance between the transmitter and the receiver up to 44%.\n",
      "Distance: 1.0505\n",
      "\n",
      "Title: Robust Charging Schedule for Autonomous Electric Vehicles With Uncertain Covariates\n",
      "Abstract: Autonomous electric vehicles (AEVs) will become an inevitable trend in the future transportation network and have an important impact on the power grid. It is difficult to find the optimal distributed charging solution for AEVs to minimize the system cost with some uncertainties. In this paper, we investigate an AEVs charging and discharging problem with vehicle-to-grid (V2G) services. We aim to minimize the total electricity cost and battery degradation cost of AEVs and charging station batteries with V2G services, which takes the random arrival and departure of AEVs into account. We first propose a distributed charging framework of AEVs and charging stations by clustering method with the constraint of limited AEVs for each charging station in a region and formulate a distributed offline optimization problem. Then we formulate a distributed online charging optimization problem and propose a distributed online AEV charging scheduling (DOAS) algorithm to get an optimal charging solution. To study a more practical case, we reformulate the distributed online optimization problem with the uncertainties from base loads, renewable energy and charging demands. Furthermore, to improve the time efficiency of DOAS algorithm, we reduce the dimension of the distributed problem and design a dimension-reduction DOAS (DDOAS) algorithm. To seek a robust solution with some uncertainties, we propose a DDOAS algorithm with DRO based on Wasserstein distance (DDODW). Simulation results show that DOAS and DDOAS algorithms can have a close-to-optimal charging cost and a significantly less battery degradation cost of charging stations, compared with centralized online charging scheduling algorithm and DDOAS algorithm is more time-efficient than DOAS algorithm. The proposed DDODW algorithm can provide a robust solution for the energy schedule\n",
      "Distance: 1.0653\n",
      "\n",
      "Title: RESHAPE: Reverse-Edited Synthetic Hypotheses for Automatic Post-Editing\n",
      "Abstract: Synthetic training data has been extensively used to train Automatic Post-Editing (APE) models in many recent studies because the quantity of human-created data has been considered insufficient. However, the most widely used synthetic APE dataset, eSCAPE, overlooks respecting the minimal editing property of genuine data, and this defect may have been a limiting factor for the performance of APE models. This article suggests adapting back-translation to APE to constrain edit distance, while using stochastic sampling in decoding to maintain the diversity of outputs, to create a new synthetic APE dataset, \n",
      "RESHAPE\n",
      ". Our experiments show that (1) RESHAPE contains more samples resembling genuine APE data than eSCAPE does, and (2) using RESHAPE as new training data improves APE modelsâ€™ performance substantially over using eSCAPE.\n",
      "Distance: 1.0682\n",
      "\n",
      "Title: Predicting Canine Posture With Smart Camera Networks Powered by the Artificial Intelligence of Things\n",
      "Abstract: In today's society, the number of people rearing pets has increased and their awareness of the need to protect pets' health has increased. Pet posture behaviour analysis and prediction are providing assistance in the medical treatment of pets. Hence, the demand for pet skeleton drawing applications has risen dramatically. Our proposed system predicts pet posture using smart camera networks powered by the artificial intelligence of things. This system is built on a platform using a Raspberry Pi embedded system. The system can determine from an image whether there is a detection target and generate a contour mask based on Mask R-CNN Technology. According to object detection, poses and key parts can be identified to predict and draw pet skeletons. Simultaneously, the behavioural action of a pet can be determined according to continuous skeleton data and then the system will actively inform the owner to perform subsequent processing.\n",
      "Distance: 1.0687\n",
      "\n",
      "Title: Deep Learning-Based Multimodal Abnormal Gait Classification Using a 3D Skeleton and Plantar Foot Pressure\n",
      "Abstract: Classification of pathological gaits has an important role in finding a weakened body part and diagnosing a disease. Many machine learning-based approaches have been proposed that automatically classify abnormal gait patterns using various sensors, such as inertial sensors, depth cameras and foot pressure plates. In this paper, we present a deep learning-based abnormal gait classification method employing both a 3D skeleton (obtained with a depth camera) and plantar foot pressure. We collected skeleton and foot pressure data simultaneously for 1 normal and 5 pathological (antalgic, lurching, steppage, stiff-legged, and Trendelenburg) gaits and classified them by using a multimodal hybrid model fed both data types together. In the proposed method, we fed the sequential skeleton and average foot pressure data into recurrent neural network (RNN)-based encoding layers and convolutional neural network (CNN)-based encoding layers, respectively, to effectively extract features from different data types. Their output features were concatenated and fed to fully connected layers for classification. The pressure-based and skeleton-based single-modal models achieved classification accuracies of 68.82% and 93.40%, respectively. The proposed multimodal hybrid model showed improved performance with an accuracy of 95.66%. We fine-tuned the hybrid model by applying a 3-step training methodology and ultimately increased the accuracy to 97.60%. This study indicates that the integrated features of the skeleton and foot pressure data represent both the spatiotemporal motion information and weight distribution, so data fusion can generate a positive effect in pathological gait classification.\n",
      "Distance: 1.0754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommend_papers(\"deep learning for edge computing\", model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3bd8b34-d743-441f-8b39-6b8162e06224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Test Embedding: tensor([ 0.0088,  0.0445, -0.0074, -0.0546,  0.0357,  0.0026, -0.0215, -0.0031,\n",
      "        -0.0073,  0.0266,  0.0360, -0.0349,  0.0086, -0.0319, -0.0079],\n",
      "       device='cuda:0')\n",
      "Sample Train Embedding: tensor([-0.0010,  0.0369,  0.0443, -0.0446, -0.0176, -0.0333, -0.0084, -0.0083,\n",
      "        -0.0205,  0.0172,  0.0678, -0.0176, -0.0244, -0.0126, -0.0247],\n",
      "       device='cuda:0')\n",
      "\n",
      "Test Paper 1:\n",
      "  1. Recommended Paper ID: 527 (Similarity: 0.8800)\n",
      "  2. Recommended Paper ID: 450 (Similarity: 0.8796)\n",
      "  3. Recommended Paper ID: 176 (Similarity: 0.8765)\n",
      "  4. Recommended Paper ID: 340 (Similarity: 0.8757)\n",
      "  5. Recommended Paper ID: 360 (Similarity: 0.8757)\n",
      "  6. Recommended Paper ID: 119 (Similarity: 0.8756)\n",
      "  7. Recommended Paper ID: 530 (Similarity: 0.8749)\n",
      "  8. Recommended Paper ID: 345 (Similarity: 0.8749)\n",
      "  9. Recommended Paper ID: 120 (Similarity: 0.8747)\n",
      "  10. Recommended Paper ID: 303 (Similarity: 0.8717)\n",
      "\n",
      "Test Paper 2:\n",
      "  1. Recommended Paper ID: 523 (Similarity: 0.8899)\n",
      "  2. Recommended Paper ID: 445 (Similarity: 0.8790)\n",
      "  3. Recommended Paper ID: 510 (Similarity: 0.8749)\n",
      "  4. Recommended Paper ID: 375 (Similarity: 0.8746)\n",
      "  5. Recommended Paper ID: 50 (Similarity: 0.8735)\n",
      "  6. Recommended Paper ID: 419 (Similarity: 0.8726)\n",
      "  7. Recommended Paper ID: 218 (Similarity: 0.8715)\n",
      "  8. Recommended Paper ID: 432 (Similarity: 0.8713)\n",
      "  9. Recommended Paper ID: 327 (Similarity: 0.8704)\n",
      "  10. Recommended Paper ID: 383 (Similarity: 0.8700)\n",
      "\n",
      "Test Paper 3:\n",
      "  1. Recommended Paper ID: 562 (Similarity: 0.9812)\n",
      "  2. Recommended Paper ID: 530 (Similarity: 0.9785)\n",
      "  3. Recommended Paper ID: 379 (Similarity: 0.9778)\n",
      "  4. Recommended Paper ID: 23 (Similarity: 0.9776)\n",
      "  5. Recommended Paper ID: 258 (Similarity: 0.9776)\n",
      "  6. Recommended Paper ID: 275 (Similarity: 0.9773)\n",
      "  7. Recommended Paper ID: 120 (Similarity: 0.9767)\n",
      "  8. Recommended Paper ID: 199 (Similarity: 0.9763)\n",
      "  9. Recommended Paper ID: 163 (Similarity: 0.9763)\n",
      "  10. Recommended Paper ID: 184 (Similarity: 0.9758)\n",
      "\n",
      "Test Paper 4:\n",
      "  1. Recommended Paper ID: 228 (Similarity: 0.9008)\n",
      "  2. Recommended Paper ID: 100 (Similarity: 0.8999)\n",
      "  3. Recommended Paper ID: 577 (Similarity: 0.8907)\n",
      "  4. Recommended Paper ID: 209 (Similarity: 0.8850)\n",
      "  5. Recommended Paper ID: 341 (Similarity: 0.8840)\n",
      "  6. Recommended Paper ID: 148 (Similarity: 0.8840)\n",
      "  7. Recommended Paper ID: 435 (Similarity: 0.8815)\n",
      "  8. Recommended Paper ID: 134 (Similarity: 0.8805)\n",
      "  9. Recommended Paper ID: 511 (Similarity: 0.8797)\n",
      "  10. Recommended Paper ID: 16 (Similarity: 0.8787)\n",
      "\n",
      "Test Paper 5:\n",
      "  1. Recommended Paper ID: 452 (Similarity: 0.9508)\n",
      "  2. Recommended Paper ID: 283 (Similarity: 0.9506)\n",
      "  3. Recommended Paper ID: 320 (Similarity: 0.9470)\n",
      "  4. Recommended Paper ID: 108 (Similarity: 0.9460)\n",
      "  5. Recommended Paper ID: 481 (Similarity: 0.9452)\n",
      "  6. Recommended Paper ID: 583 (Similarity: 0.9447)\n",
      "  7. Recommended Paper ID: 94 (Similarity: 0.9441)\n",
      "  8. Recommended Paper ID: 68 (Similarity: 0.9436)\n",
      "  9. Recommended Paper ID: 379 (Similarity: 0.9433)\n",
      "  10. Recommended Paper ID: 494 (Similarity: 0.9431)\n",
      "\n",
      "Test Paper 6:\n",
      "  1. Recommended Paper ID: 5 (Similarity: 0.8816)\n",
      "  2. Recommended Paper ID: 133 (Similarity: 0.8755)\n",
      "  3. Recommended Paper ID: 201 (Similarity: 0.8691)\n",
      "  4. Recommended Paper ID: 562 (Similarity: 0.8662)\n",
      "  5. Recommended Paper ID: 180 (Similarity: 0.8646)\n",
      "  6. Recommended Paper ID: 300 (Similarity: 0.8632)\n",
      "  7. Recommended Paper ID: 100 (Similarity: 0.8624)\n",
      "  8. Recommended Paper ID: 148 (Similarity: 0.8622)\n",
      "  9. Recommended Paper ID: 30 (Similarity: 0.8621)\n",
      "  10. Recommended Paper ID: 459 (Similarity: 0.8619)\n",
      "\n",
      "Test Paper 7:\n",
      "  1. Recommended Paper ID: 530 (Similarity: 0.9442)\n",
      "  2. Recommended Paper ID: 218 (Similarity: 0.9412)\n",
      "  3. Recommended Paper ID: 144 (Similarity: 0.9399)\n",
      "  4. Recommended Paper ID: 448 (Similarity: 0.9385)\n",
      "  5. Recommended Paper ID: 256 (Similarity: 0.9375)\n",
      "  6. Recommended Paper ID: 556 (Similarity: 0.9362)\n",
      "  7. Recommended Paper ID: 163 (Similarity: 0.9343)\n",
      "  8. Recommended Paper ID: 359 (Similarity: 0.9337)\n",
      "  9. Recommended Paper ID: 119 (Similarity: 0.9336)\n",
      "  10. Recommended Paper ID: 395 (Similarity: 0.9334)\n",
      "\n",
      "Test Paper 8:\n",
      "  1. Recommended Paper ID: 94 (Similarity: 0.8946)\n",
      "  2. Recommended Paper ID: 420 (Similarity: 0.8934)\n",
      "  3. Recommended Paper ID: 227 (Similarity: 0.8829)\n",
      "  4. Recommended Paper ID: 43 (Similarity: 0.8804)\n",
      "  5. Recommended Paper ID: 575 (Similarity: 0.8790)\n",
      "  6. Recommended Paper ID: 221 (Similarity: 0.8789)\n",
      "  7. Recommended Paper ID: 68 (Similarity: 0.8773)\n",
      "  8. Recommended Paper ID: 124 (Similarity: 0.8766)\n",
      "  9. Recommended Paper ID: 557 (Similarity: 0.8765)\n",
      "  10. Recommended Paper ID: 590 (Similarity: 0.8757)\n",
      "\n",
      "Test Paper 9:\n",
      "  1. Recommended Paper ID: 166 (Similarity: 0.9303)\n",
      "  2. Recommended Paper ID: 227 (Similarity: 0.9281)\n",
      "  3. Recommended Paper ID: 393 (Similarity: 0.9236)\n",
      "  4. Recommended Paper ID: 583 (Similarity: 0.9227)\n",
      "  5. Recommended Paper ID: 94 (Similarity: 0.9218)\n",
      "  6. Recommended Paper ID: 61 (Similarity: 0.9204)\n",
      "  7. Recommended Paper ID: 68 (Similarity: 0.9195)\n",
      "  8. Recommended Paper ID: 435 (Similarity: 0.9185)\n",
      "  9. Recommended Paper ID: 312 (Similarity: 0.9184)\n",
      "  10. Recommended Paper ID: 590 (Similarity: 0.9177)\n",
      "\n",
      "Test Paper 10:\n",
      "  1. Recommended Paper ID: 283 (Similarity: 0.9364)\n",
      "  2. Recommended Paper ID: 383 (Similarity: 0.9311)\n",
      "  3. Recommended Paper ID: 583 (Similarity: 0.9310)\n",
      "  4. Recommended Paper ID: 52 (Similarity: 0.9285)\n",
      "  5. Recommended Paper ID: 379 (Similarity: 0.9283)\n",
      "  6. Recommended Paper ID: 258 (Similarity: 0.9282)\n",
      "  7. Recommended Paper ID: 477 (Similarity: 0.9279)\n",
      "  8. Recommended Paper ID: 65 (Similarity: 0.9272)\n",
      "  9. Recommended Paper ID: 174 (Similarity: 0.9271)\n",
      "  10. Recommended Paper ID: 47 (Similarity: 0.9269)\n",
      "\n",
      "Test Paper 11:\n",
      "  1. Recommended Paper ID: 47 (Similarity: 0.9810)\n",
      "  2. Recommended Paper ID: 452 (Similarity: 0.9757)\n",
      "  3. Recommended Paper ID: 25 (Similarity: 0.9757)\n",
      "  4. Recommended Paper ID: 126 (Similarity: 0.9755)\n",
      "  5. Recommended Paper ID: 65 (Similarity: 0.9754)\n",
      "  6. Recommended Paper ID: 279 (Similarity: 0.9746)\n",
      "  7. Recommended Paper ID: 440 (Similarity: 0.9743)\n",
      "  8. Recommended Paper ID: 379 (Similarity: 0.9727)\n",
      "  9. Recommended Paper ID: 558 (Similarity: 0.9726)\n",
      "  10. Recommended Paper ID: 241 (Similarity: 0.9722)\n",
      "\n",
      "Test Paper 12:\n",
      "  1. Recommended Paper ID: 575 (Similarity: 0.8058)\n",
      "  2. Recommended Paper ID: 179 (Similarity: 0.7979)\n",
      "  3. Recommended Paper ID: 327 (Similarity: 0.7938)\n",
      "  4. Recommended Paper ID: 16 (Similarity: 0.7933)\n",
      "  5. Recommended Paper ID: 331 (Similarity: 0.7932)\n",
      "  6. Recommended Paper ID: 557 (Similarity: 0.7917)\n",
      "  7. Recommended Paper ID: 312 (Similarity: 0.7914)\n",
      "  8. Recommended Paper ID: 98 (Similarity: 0.7913)\n",
      "  9. Recommended Paper ID: 504 (Similarity: 0.7899)\n",
      "  10. Recommended Paper ID: 228 (Similarity: 0.7897)\n",
      "\n",
      "Test Paper 13:\n",
      "  1. Recommended Paper ID: 369 (Similarity: 0.8247)\n",
      "  2. Recommended Paper ID: 216 (Similarity: 0.8119)\n",
      "  3. Recommended Paper ID: 385 (Similarity: 0.7451)\n",
      "  4. Recommended Paper ID: 63 (Similarity: 0.6944)\n",
      "  5. Recommended Paper ID: 41 (Similarity: 0.6930)\n",
      "  6. Recommended Paper ID: 373 (Similarity: 0.6876)\n",
      "  7. Recommended Paper ID: 31 (Similarity: 0.6568)\n",
      "  8. Recommended Paper ID: 338 (Similarity: 0.6505)\n",
      "  9. Recommended Paper ID: 133 (Similarity: 0.6502)\n",
      "  10. Recommended Paper ID: 365 (Similarity: 0.6412)\n",
      "\n",
      "Test Paper 14:\n",
      "  1. Recommended Paper ID: 406 (Similarity: 0.9175)\n",
      "  2. Recommended Paper ID: 19 (Similarity: 0.9121)\n",
      "  3. Recommended Paper ID: 159 (Similarity: 0.9092)\n",
      "  4. Recommended Paper ID: 395 (Similarity: 0.9063)\n",
      "  5. Recommended Paper ID: 120 (Similarity: 0.9037)\n",
      "  6. Recommended Paper ID: 180 (Similarity: 0.9034)\n",
      "  7. Recommended Paper ID: 176 (Similarity: 0.9032)\n",
      "  8. Recommended Paper ID: 312 (Similarity: 0.9030)\n",
      "  9. Recommended Paper ID: 137 (Similarity: 0.9027)\n",
      "  10. Recommended Paper ID: 69 (Similarity: 0.9025)\n",
      "\n",
      "Test Paper 15:\n",
      "  1. Recommended Paper ID: 527 (Similarity: 0.8545)\n",
      "  2. Recommended Paper ID: 354 (Similarity: 0.8520)\n",
      "  3. Recommended Paper ID: 317 (Similarity: 0.8390)\n",
      "  4. Recommended Paper ID: 159 (Similarity: 0.8354)\n",
      "  5. Recommended Paper ID: 98 (Similarity: 0.8307)\n",
      "  6. Recommended Paper ID: 445 (Similarity: 0.8306)\n",
      "  7. Recommended Paper ID: 386 (Similarity: 0.8302)\n",
      "  8. Recommended Paper ID: 209 (Similarity: 0.8290)\n",
      "  9. Recommended Paper ID: 120 (Similarity: 0.8286)\n",
      "  10. Recommended Paper ID: 577 (Similarity: 0.8271)\n",
      "\n",
      "Test Paper 16:\n",
      "  1. Recommended Paper ID: 395 (Similarity: 0.8746)\n",
      "  2. Recommended Paper ID: 383 (Similarity: 0.8732)\n",
      "  3. Recommended Paper ID: 516 (Similarity: 0.8730)\n",
      "  4. Recommended Paper ID: 68 (Similarity: 0.8729)\n",
      "  5. Recommended Paper ID: 562 (Similarity: 0.8727)\n",
      "  6. Recommended Paper ID: 23 (Similarity: 0.8726)\n",
      "  7. Recommended Paper ID: 180 (Similarity: 0.8715)\n",
      "  8. Recommended Paper ID: 148 (Similarity: 0.8714)\n",
      "  9. Recommended Paper ID: 457 (Similarity: 0.8711)\n",
      "  10. Recommended Paper ID: 174 (Similarity: 0.8708)\n",
      "\n",
      "Test Paper 17:\n",
      "  1. Recommended Paper ID: 283 (Similarity: 0.9391)\n",
      "  2. Recommended Paper ID: 289 (Similarity: 0.9358)\n",
      "  3. Recommended Paper ID: 563 (Similarity: 0.9353)\n",
      "  4. Recommended Paper ID: 477 (Similarity: 0.9351)\n",
      "  5. Recommended Paper ID: 507 (Similarity: 0.9344)\n",
      "  6. Recommended Paper ID: 558 (Similarity: 0.9306)\n",
      "  7. Recommended Paper ID: 535 (Similarity: 0.9292)\n",
      "  8. Recommended Paper ID: 383 (Similarity: 0.9289)\n",
      "  9. Recommended Paper ID: 583 (Similarity: 0.9278)\n",
      "  10. Recommended Paper ID: 258 (Similarity: 0.9276)\n",
      "\n",
      "Test Paper 18:\n",
      "  1. Recommended Paper ID: 38 (Similarity: 0.8136)\n",
      "  2. Recommended Paper ID: 534 (Similarity: 0.8029)\n",
      "  3. Recommended Paper ID: 328 (Similarity: 0.8006)\n",
      "  4. Recommended Paper ID: 333 (Similarity: 0.7987)\n",
      "  5. Recommended Paper ID: 577 (Similarity: 0.7970)\n",
      "  6. Recommended Paper ID: 312 (Similarity: 0.7965)\n",
      "  7. Recommended Paper ID: 300 (Similarity: 0.7962)\n",
      "  8. Recommended Paper ID: 108 (Similarity: 0.7941)\n",
      "  9. Recommended Paper ID: 583 (Similarity: 0.7936)\n",
      "  10. Recommended Paper ID: 445 (Similarity: 0.7933)\n",
      "\n",
      "Test Paper 19:\n",
      "  1. Recommended Paper ID: 419 (Similarity: 0.9051)\n",
      "  2. Recommended Paper ID: 209 (Similarity: 0.9043)\n",
      "  3. Recommended Paper ID: 445 (Similarity: 0.9041)\n",
      "  4. Recommended Paper ID: 283 (Similarity: 0.9038)\n",
      "  5. Recommended Paper ID: 556 (Similarity: 0.9019)\n",
      "  6. Recommended Paper ID: 163 (Similarity: 0.9000)\n",
      "  7. Recommended Paper ID: 312 (Similarity: 0.8997)\n",
      "  8. Recommended Paper ID: 7 (Similarity: 0.8996)\n",
      "  9. Recommended Paper ID: 113 (Similarity: 0.8991)\n",
      "  10. Recommended Paper ID: 120 (Similarity: 0.8988)\n",
      "\n",
      "Test Paper 20:\n",
      "  1. Recommended Paper ID: 44 (Similarity: 0.8964)\n",
      "  2. Recommended Paper ID: 590 (Similarity: 0.8921)\n",
      "  3. Recommended Paper ID: 538 (Similarity: 0.8903)\n",
      "  4. Recommended Paper ID: 294 (Similarity: 0.8877)\n",
      "  5. Recommended Paper ID: 278 (Similarity: 0.8876)\n",
      "  6. Recommended Paper ID: 166 (Similarity: 0.8852)\n",
      "  7. Recommended Paper ID: 352 (Similarity: 0.8847)\n",
      "  8. Recommended Paper ID: 281 (Similarity: 0.8837)\n",
      "  9. Recommended Paper ID: 68 (Similarity: 0.8828)\n",
      "  10. Recommended Paper ID: 199 (Similarity: 0.8825)\n",
      "\n",
      "Test Paper 21:\n",
      "  1. Recommended Paper ID: 435 (Similarity: 0.8879)\n",
      "  2. Recommended Paper ID: 283 (Similarity: 0.8841)\n",
      "  3. Recommended Paper ID: 120 (Similarity: 0.8822)\n",
      "  4. Recommended Paper ID: 52 (Similarity: 0.8821)\n",
      "  5. Recommended Paper ID: 530 (Similarity: 0.8802)\n",
      "  6. Recommended Paper ID: 180 (Similarity: 0.8800)\n",
      "  7. Recommended Paper ID: 137 (Similarity: 0.8797)\n",
      "  8. Recommended Paper ID: 199 (Similarity: 0.8793)\n",
      "  9. Recommended Paper ID: 597 (Similarity: 0.8792)\n",
      "  10. Recommended Paper ID: 98 (Similarity: 0.8791)\n",
      "\n",
      "Test Paper 22:\n",
      "  1. Recommended Paper ID: 109 (Similarity: 0.9705)\n",
      "  2. Recommended Paper ID: 23 (Similarity: 0.9693)\n",
      "  3. Recommended Paper ID: 383 (Similarity: 0.9690)\n",
      "  4. Recommended Paper ID: 258 (Similarity: 0.9664)\n",
      "  5. Recommended Paper ID: 124 (Similarity: 0.9664)\n",
      "  6. Recommended Paper ID: 184 (Similarity: 0.9661)\n",
      "  7. Recommended Paper ID: 180 (Similarity: 0.9659)\n",
      "  8. Recommended Paper ID: 562 (Similarity: 0.9645)\n",
      "  9. Recommended Paper ID: 126 (Similarity: 0.9638)\n",
      "  10. Recommended Paper ID: 496 (Similarity: 0.9638)\n",
      "\n",
      "Test Paper 23:\n",
      "  1. Recommended Paper ID: 562 (Similarity: 0.8981)\n",
      "  2. Recommended Paper ID: 185 (Similarity: 0.8975)\n",
      "  3. Recommended Paper ID: 445 (Similarity: 0.8973)\n",
      "  4. Recommended Paper ID: 241 (Similarity: 0.8969)\n",
      "  5. Recommended Paper ID: 53 (Similarity: 0.8942)\n",
      "  6. Recommended Paper ID: 327 (Similarity: 0.8942)\n",
      "  7. Recommended Paper ID: 464 (Similarity: 0.8937)\n",
      "  8. Recommended Paper ID: 199 (Similarity: 0.8936)\n",
      "  9. Recommended Paper ID: 119 (Similarity: 0.8936)\n",
      "  10. Recommended Paper ID: 144 (Similarity: 0.8935)\n",
      "\n",
      "Test Paper 24:\n",
      "  1. Recommended Paper ID: 47 (Similarity: 0.9524)\n",
      "  2. Recommended Paper ID: 25 (Similarity: 0.9412)\n",
      "  3. Recommended Paper ID: 388 (Similarity: 0.9403)\n",
      "  4. Recommended Paper ID: 383 (Similarity: 0.9388)\n",
      "  5. Recommended Paper ID: 566 (Similarity: 0.9385)\n",
      "  6. Recommended Paper ID: 152 (Similarity: 0.9383)\n",
      "  7. Recommended Paper ID: 529 (Similarity: 0.9373)\n",
      "  8. Recommended Paper ID: 563 (Similarity: 0.9369)\n",
      "  9. Recommended Paper ID: 279 (Similarity: 0.9366)\n",
      "  10. Recommended Paper ID: 241 (Similarity: 0.9363)\n",
      "\n",
      "Test Paper 25:\n",
      "  1. Recommended Paper ID: 395 (Similarity: 0.8828)\n",
      "  2. Recommended Paper ID: 577 (Similarity: 0.8798)\n",
      "  3. Recommended Paper ID: 328 (Similarity: 0.8794)\n",
      "  4. Recommended Paper ID: 527 (Similarity: 0.8781)\n",
      "  5. Recommended Paper ID: 98 (Similarity: 0.8766)\n",
      "  6. Recommended Paper ID: 119 (Similarity: 0.8755)\n",
      "  7. Recommended Paper ID: 312 (Similarity: 0.8741)\n",
      "  8. Recommended Paper ID: 418 (Similarity: 0.8731)\n",
      "  9. Recommended Paper ID: 345 (Similarity: 0.8730)\n",
      "  10. Recommended Paper ID: 435 (Similarity: 0.8718)\n",
      "\n",
      "Test Paper 26:\n",
      "  1. Recommended Paper ID: 119 (Similarity: 0.9654)\n",
      "  2. Recommended Paper ID: 163 (Similarity: 0.9646)\n",
      "  3. Recommended Paper ID: 258 (Similarity: 0.9633)\n",
      "  4. Recommended Paper ID: 514 (Similarity: 0.9627)\n",
      "  5. Recommended Paper ID: 98 (Similarity: 0.9625)\n",
      "  6. Recommended Paper ID: 489 (Similarity: 0.9621)\n",
      "  7. Recommended Paper ID: 218 (Similarity: 0.9618)\n",
      "  8. Recommended Paper ID: 383 (Similarity: 0.9618)\n",
      "  9. Recommended Paper ID: 65 (Similarity: 0.9618)\n",
      "  10. Recommended Paper ID: 530 (Similarity: 0.9617)\n",
      "\n",
      "Test Paper 27:\n",
      "  1. Recommended Paper ID: 161 (Similarity: 0.8426)\n",
      "  2. Recommended Paper ID: 166 (Similarity: 0.8379)\n",
      "  3. Recommended Paper ID: 493 (Similarity: 0.8376)\n",
      "  4. Recommended Paper ID: 563 (Similarity: 0.8253)\n",
      "  5. Recommended Paper ID: 311 (Similarity: 0.8210)\n",
      "  6. Recommended Paper ID: 259 (Similarity: 0.8175)\n",
      "  7. Recommended Paper ID: 297 (Similarity: 0.8169)\n",
      "  8. Recommended Paper ID: 529 (Similarity: 0.8159)\n",
      "  9. Recommended Paper ID: 176 (Similarity: 0.8156)\n",
      "  10. Recommended Paper ID: 492 (Similarity: 0.8153)\n",
      "\n",
      "Test Paper 28:\n",
      "  1. Recommended Paper ID: 327 (Similarity: 0.9252)\n",
      "  2. Recommended Paper ID: 23 (Similarity: 0.9217)\n",
      "  3. Recommended Paper ID: 108 (Similarity: 0.9214)\n",
      "  4. Recommended Paper ID: 371 (Similarity: 0.9212)\n",
      "  5. Recommended Paper ID: 97 (Similarity: 0.9206)\n",
      "  6. Recommended Paper ID: 388 (Similarity: 0.9201)\n",
      "  7. Recommended Paper ID: 478 (Similarity: 0.9194)\n",
      "  8. Recommended Paper ID: 180 (Similarity: 0.9193)\n",
      "  9. Recommended Paper ID: 419 (Similarity: 0.9189)\n",
      "  10. Recommended Paper ID: 320 (Similarity: 0.9185)\n",
      "\n",
      "Test Paper 29:\n",
      "  1. Recommended Paper ID: 233 (Similarity: 0.8493)\n",
      "  2. Recommended Paper ID: 347 (Similarity: 0.7159)\n",
      "  3. Recommended Paper ID: 306 (Similarity: 0.6045)\n",
      "  4. Recommended Paper ID: 268 (Similarity: 0.5979)\n",
      "  5. Recommended Paper ID: 517 (Similarity: 0.5978)\n",
      "  6. Recommended Paper ID: 261 (Similarity: 0.5951)\n",
      "  7. Recommended Paper ID: 129 (Similarity: 0.5918)\n",
      "  8. Recommended Paper ID: 43 (Similarity: 0.5901)\n",
      "  9. Recommended Paper ID: 484 (Similarity: 0.5795)\n",
      "  10. Recommended Paper ID: 525 (Similarity: 0.5792)\n",
      "\n",
      "Test Paper 30:\n",
      "  1. Recommended Paper ID: 436 (Similarity: 0.7623)\n",
      "  2. Recommended Paper ID: 431 (Similarity: 0.7443)\n",
      "  3. Recommended Paper ID: 354 (Similarity: 0.7415)\n",
      "  4. Recommended Paper ID: 534 (Similarity: 0.7261)\n",
      "  5. Recommended Paper ID: 151 (Similarity: 0.7227)\n",
      "  6. Recommended Paper ID: 537 (Similarity: 0.7217)\n",
      "  7. Recommended Paper ID: 527 (Similarity: 0.7174)\n",
      "  8. Recommended Paper ID: 547 (Similarity: 0.7169)\n",
      "  9. Recommended Paper ID: 8 (Similarity: 0.7160)\n",
      "  10. Recommended Paper ID: 312 (Similarity: 0.7155)\n",
      "\n",
      "Test Paper 31:\n",
      "  1. Recommended Paper ID: 8 (Similarity: 0.9035)\n",
      "  2. Recommended Paper ID: 527 (Similarity: 0.9016)\n",
      "  3. Recommended Paper ID: 418 (Similarity: 0.8980)\n",
      "  4. Recommended Paper ID: 312 (Similarity: 0.8965)\n",
      "  5. Recommended Paper ID: 98 (Similarity: 0.8914)\n",
      "  6. Recommended Paper ID: 14 (Similarity: 0.8907)\n",
      "  7. Recommended Paper ID: 435 (Similarity: 0.8871)\n",
      "  8. Recommended Paper ID: 176 (Similarity: 0.8866)\n",
      "  9. Recommended Paper ID: 120 (Similarity: 0.8865)\n",
      "  10. Recommended Paper ID: 311 (Similarity: 0.8859)\n",
      "\n",
      "Test Paper 32:\n",
      "  1. Recommended Paper ID: 109 (Similarity: 0.9606)\n",
      "  2. Recommended Paper ID: 221 (Similarity: 0.9592)\n",
      "  3. Recommended Paper ID: 383 (Similarity: 0.9585)\n",
      "  4. Recommended Paper ID: 47 (Similarity: 0.9584)\n",
      "  5. Recommended Paper ID: 379 (Similarity: 0.9583)\n",
      "  6. Recommended Paper ID: 23 (Similarity: 0.9580)\n",
      "  7. Recommended Paper ID: 496 (Similarity: 0.9575)\n",
      "  8. Recommended Paper ID: 495 (Similarity: 0.9574)\n",
      "  9. Recommended Paper ID: 478 (Similarity: 0.9572)\n",
      "  10. Recommended Paper ID: 152 (Similarity: 0.9571)\n",
      "\n",
      "Test Paper 33:\n",
      "  1. Recommended Paper ID: 221 (Similarity: 0.9337)\n",
      "  2. Recommended Paper ID: 492 (Similarity: 0.9329)\n",
      "  3. Recommended Paper ID: 536 (Similarity: 0.9326)\n",
      "  4. Recommended Paper ID: 529 (Similarity: 0.9313)\n",
      "  5. Recommended Paper ID: 379 (Similarity: 0.9311)\n",
      "  6. Recommended Paper ID: 352 (Similarity: 0.9304)\n",
      "  7. Recommended Paper ID: 180 (Similarity: 0.9300)\n",
      "  8. Recommended Paper ID: 281 (Similarity: 0.9291)\n",
      "  9. Recommended Paper ID: 152 (Similarity: 0.9290)\n",
      "  10. Recommended Paper ID: 558 (Similarity: 0.9290)\n",
      "\n",
      "Test Paper 34:\n",
      "  1. Recommended Paper ID: 386 (Similarity: 0.9306)\n",
      "  2. Recommended Paper ID: 530 (Similarity: 0.9288)\n",
      "  3. Recommended Paper ID: 445 (Similarity: 0.9254)\n",
      "  4. Recommended Paper ID: 597 (Similarity: 0.9246)\n",
      "  5. Recommended Paper ID: 589 (Similarity: 0.9244)\n",
      "  6. Recommended Paper ID: 559 (Similarity: 0.9242)\n",
      "  7. Recommended Paper ID: 562 (Similarity: 0.9240)\n",
      "  8. Recommended Paper ID: 557 (Similarity: 0.9235)\n",
      "  9. Recommended Paper ID: 383 (Similarity: 0.9234)\n",
      "  10. Recommended Paper ID: 512 (Similarity: 0.9234)\n",
      "\n",
      "Test Paper 35:\n",
      "  1. Recommended Paper ID: 161 (Similarity: 0.8575)\n",
      "  2. Recommended Paper ID: 564 (Similarity: 0.8130)\n",
      "  3. Recommended Paper ID: 367 (Similarity: 0.8081)\n",
      "  4. Recommended Paper ID: 448 (Similarity: 0.7937)\n",
      "  5. Recommended Paper ID: 493 (Similarity: 0.7875)\n",
      "  6. Recommended Paper ID: 432 (Similarity: 0.7873)\n",
      "  7. Recommended Paper ID: 38 (Similarity: 0.7841)\n",
      "  8. Recommended Paper ID: 464 (Similarity: 0.7793)\n",
      "  9. Recommended Paper ID: 176 (Similarity: 0.7790)\n",
      "  10. Recommended Paper ID: 360 (Similarity: 0.7781)\n",
      "\n",
      "Test Paper 36:\n",
      "  1. Recommended Paper ID: 590 (Similarity: 0.9300)\n",
      "  2. Recommended Paper ID: 44 (Similarity: 0.9280)\n",
      "  3. Recommended Paper ID: 464 (Similarity: 0.9225)\n",
      "  4. Recommended Paper ID: 176 (Similarity: 0.9223)\n",
      "  5. Recommended Paper ID: 199 (Similarity: 0.9220)\n",
      "  6. Recommended Paper ID: 352 (Similarity: 0.9210)\n",
      "  7. Recommended Paper ID: 329 (Similarity: 0.9210)\n",
      "  8. Recommended Paper ID: 530 (Similarity: 0.9202)\n",
      "  9. Recommended Paper ID: 379 (Similarity: 0.9196)\n",
      "  10. Recommended Paper ID: 227 (Similarity: 0.9193)\n",
      "\n",
      "Test Paper 37:\n",
      "  1. Recommended Paper ID: 327 (Similarity: 0.9304)\n",
      "  2. Recommended Paper ID: 559 (Similarity: 0.9293)\n",
      "  3. Recommended Paper ID: 68 (Similarity: 0.9273)\n",
      "  4. Recommended Paper ID: 23 (Similarity: 0.9261)\n",
      "  5. Recommended Paper ID: 258 (Similarity: 0.9256)\n",
      "  6. Recommended Paper ID: 199 (Similarity: 0.9255)\n",
      "  7. Recommended Paper ID: 378 (Similarity: 0.9249)\n",
      "  8. Recommended Paper ID: 97 (Similarity: 0.9244)\n",
      "  9. Recommended Paper ID: 221 (Similarity: 0.9240)\n",
      "  10. Recommended Paper ID: 180 (Similarity: 0.9239)\n",
      "\n",
      "Test Paper 38:\n",
      "  1. Recommended Paper ID: 209 (Similarity: 0.9061)\n",
      "  2. Recommended Paper ID: 292 (Similarity: 0.9057)\n",
      "  3. Recommended Paper ID: 445 (Similarity: 0.9048)\n",
      "  4. Recommended Paper ID: 406 (Similarity: 0.9046)\n",
      "  5. Recommended Paper ID: 242 (Similarity: 0.9039)\n",
      "  6. Recommended Paper ID: 530 (Similarity: 0.9037)\n",
      "  7. Recommended Paper ID: 163 (Similarity: 0.9026)\n",
      "  8. Recommended Paper ID: 119 (Similarity: 0.9023)\n",
      "  9. Recommended Paper ID: 227 (Similarity: 0.9009)\n",
      "  10. Recommended Paper ID: 386 (Similarity: 0.9002)\n",
      "\n",
      "Test Paper 39:\n",
      "  1. Recommended Paper ID: 133 (Similarity: 0.8908)\n",
      "  2. Recommended Paper ID: 201 (Similarity: 0.8697)\n",
      "  3. Recommended Paper ID: 338 (Similarity: 0.8399)\n",
      "  4. Recommended Paper ID: 5 (Similarity: 0.8397)\n",
      "  5. Recommended Paper ID: 459 (Similarity: 0.8308)\n",
      "  6. Recommended Paper ID: 562 (Similarity: 0.8290)\n",
      "  7. Recommended Paper ID: 502 (Similarity: 0.8269)\n",
      "  8. Recommended Paper ID: 299 (Similarity: 0.8264)\n",
      "  9. Recommended Paper ID: 30 (Similarity: 0.8257)\n",
      "  10. Recommended Paper ID: 227 (Similarity: 0.8228)\n",
      "\n",
      "Test Paper 40:\n",
      "  1. Recommended Paper ID: 426 (Similarity: 0.7998)\n",
      "  2. Recommended Paper ID: 406 (Similarity: 0.7871)\n",
      "  3. Recommended Paper ID: 562 (Similarity: 0.7857)\n",
      "  4. Recommended Paper ID: 386 (Similarity: 0.7835)\n",
      "  5. Recommended Paper ID: 285 (Similarity: 0.7829)\n",
      "  6. Recommended Paper ID: 64 (Similarity: 0.7829)\n",
      "  7. Recommended Paper ID: 395 (Similarity: 0.7828)\n",
      "  8. Recommended Paper ID: 341 (Similarity: 0.7822)\n",
      "  9. Recommended Paper ID: 176 (Similarity: 0.7815)\n",
      "  10. Recommended Paper ID: 312 (Similarity: 0.7810)\n",
      "\n",
      "Test Paper 41:\n",
      "  1. Recommended Paper ID: 227 (Similarity: 0.8858)\n",
      "  2. Recommended Paper ID: 166 (Similarity: 0.8844)\n",
      "  3. Recommended Paper ID: 275 (Similarity: 0.8812)\n",
      "  4. Recommended Paper ID: 114 (Similarity: 0.8794)\n",
      "  5. Recommended Paper ID: 61 (Similarity: 0.8786)\n",
      "  6. Recommended Paper ID: 312 (Similarity: 0.8774)\n",
      "  7. Recommended Paper ID: 176 (Similarity: 0.8768)\n",
      "  8. Recommended Paper ID: 179 (Similarity: 0.8766)\n",
      "  9. Recommended Paper ID: 69 (Similarity: 0.8757)\n",
      "  10. Recommended Paper ID: 530 (Similarity: 0.8750)\n",
      "\n",
      "Test Paper 42:\n",
      "  1. Recommended Paper ID: 527 (Similarity: 0.9151)\n",
      "  2. Recommended Paper ID: 300 (Similarity: 0.9116)\n",
      "  3. Recommended Paper ID: 119 (Similarity: 0.9107)\n",
      "  4. Recommended Paper ID: 513 (Similarity: 0.9102)\n",
      "  5. Recommended Paper ID: 14 (Similarity: 0.9101)\n",
      "  6. Recommended Paper ID: 445 (Similarity: 0.9099)\n",
      "  7. Recommended Paper ID: 377 (Similarity: 0.9095)\n",
      "  8. Recommended Paper ID: 98 (Similarity: 0.9095)\n",
      "  9. Recommended Paper ID: 163 (Similarity: 0.9088)\n",
      "  10. Recommended Paper ID: 597 (Similarity: 0.9086)\n",
      "\n",
      "Test Paper 43:\n",
      "  1. Recommended Paper ID: 41 (Similarity: 0.9284)\n",
      "  2. Recommended Paper ID: 214 (Similarity: 0.8898)\n",
      "  3. Recommended Paper ID: 119 (Similarity: 0.8794)\n",
      "  4. Recommended Paper ID: 53 (Similarity: 0.8635)\n",
      "  5. Recommended Paper ID: 120 (Similarity: 0.8630)\n",
      "  6. Recommended Paper ID: 14 (Similarity: 0.8623)\n",
      "  7. Recommended Paper ID: 363 (Similarity: 0.8610)\n",
      "  8. Recommended Paper ID: 597 (Similarity: 0.8606)\n",
      "  9. Recommended Paper ID: 312 (Similarity: 0.8605)\n",
      "  10. Recommended Paper ID: 148 (Similarity: 0.8603)\n",
      "\n",
      "Test Paper 44:\n",
      "  1. Recommended Paper ID: 218 (Similarity: 0.9407)\n",
      "  2. Recommended Paper ID: 445 (Similarity: 0.9392)\n",
      "  3. Recommended Paper ID: 523 (Similarity: 0.9390)\n",
      "  4. Recommended Paper ID: 510 (Similarity: 0.9317)\n",
      "  5. Recommended Paper ID: 375 (Similarity: 0.9313)\n",
      "  6. Recommended Paper ID: 174 (Similarity: 0.9312)\n",
      "  7. Recommended Paper ID: 292 (Similarity: 0.9300)\n",
      "  8. Recommended Paper ID: 23 (Similarity: 0.9299)\n",
      "  9. Recommended Paper ID: 50 (Similarity: 0.9299)\n",
      "  10. Recommended Paper ID: 432 (Similarity: 0.9298)\n",
      "\n",
      "Test Paper 45:\n",
      "  1. Recommended Paper ID: 450 (Similarity: 0.9022)\n",
      "  2. Recommended Paper ID: 513 (Similarity: 0.9019)\n",
      "  3. Recommended Paper ID: 53 (Similarity: 0.9014)\n",
      "  4. Recommended Paper ID: 119 (Similarity: 0.9000)\n",
      "  5. Recommended Paper ID: 557 (Similarity: 0.8996)\n",
      "  6. Recommended Paper ID: 514 (Similarity: 0.8972)\n",
      "  7. Recommended Paper ID: 209 (Similarity: 0.8969)\n",
      "  8. Recommended Paper ID: 562 (Similarity: 0.8965)\n",
      "  9. Recommended Paper ID: 185 (Similarity: 0.8961)\n",
      "  10. Recommended Paper ID: 445 (Similarity: 0.8927)\n",
      "\n",
      "Test Paper 46:\n",
      "  1. Recommended Paper ID: 201 (Similarity: 0.8264)\n",
      "  2. Recommended Paper ID: 133 (Similarity: 0.8230)\n",
      "  3. Recommended Paper ID: 338 (Similarity: 0.8133)\n",
      "  4. Recommended Paper ID: 208 (Similarity: 0.8091)\n",
      "  5. Recommended Paper ID: 121 (Similarity: 0.7622)\n",
      "  6. Recommended Paper ID: 394 (Similarity: 0.7602)\n",
      "  7. Recommended Paper ID: 317 (Similarity: 0.7544)\n",
      "  8. Recommended Paper ID: 354 (Similarity: 0.7528)\n",
      "  9. Recommended Paper ID: 527 (Similarity: 0.7413)\n",
      "  10. Recommended Paper ID: 43 (Similarity: 0.7392)\n",
      "\n",
      "Test Paper 47:\n",
      "  1. Recommended Paper ID: 303 (Similarity: 0.9390)\n",
      "  2. Recommended Paper ID: 530 (Similarity: 0.9379)\n",
      "  3. Recommended Paper ID: 256 (Similarity: 0.9358)\n",
      "  4. Recommended Paper ID: 218 (Similarity: 0.9358)\n",
      "  5. Recommended Paper ID: 478 (Similarity: 0.9351)\n",
      "  6. Recommended Paper ID: 448 (Similarity: 0.9349)\n",
      "  7. Recommended Paper ID: 144 (Similarity: 0.9343)\n",
      "  8. Recommended Paper ID: 559 (Similarity: 0.9339)\n",
      "  9. Recommended Paper ID: 514 (Similarity: 0.9335)\n",
      "  10. Recommended Paper ID: 205 (Similarity: 0.9331)\n",
      "\n",
      "Test Paper 48:\n",
      "  1. Recommended Paper ID: 8 (Similarity: 0.8997)\n",
      "  2. Recommended Paper ID: 547 (Similarity: 0.8962)\n",
      "  3. Recommended Paper ID: 418 (Similarity: 0.8883)\n",
      "  4. Recommended Paper ID: 98 (Similarity: 0.8807)\n",
      "  5. Recommended Paper ID: 527 (Similarity: 0.8766)\n",
      "  6. Recommended Paper ID: 312 (Similarity: 0.8732)\n",
      "  7. Recommended Paper ID: 457 (Similarity: 0.8723)\n",
      "  8. Recommended Paper ID: 38 (Similarity: 0.8708)\n",
      "  9. Recommended Paper ID: 445 (Similarity: 0.8707)\n",
      "  10. Recommended Paper ID: 209 (Similarity: 0.8707)\n",
      "\n",
      "Test Paper 49:\n",
      "  1. Recommended Paper ID: 395 (Similarity: 0.9554)\n",
      "  2. Recommended Paper ID: 199 (Similarity: 0.9538)\n",
      "  3. Recommended Paper ID: 152 (Similarity: 0.9524)\n",
      "  4. Recommended Paper ID: 522 (Similarity: 0.9522)\n",
      "  5. Recommended Paper ID: 562 (Similarity: 0.9516)\n",
      "  6. Recommended Paper ID: 435 (Similarity: 0.9514)\n",
      "  7. Recommended Paper ID: 227 (Similarity: 0.9512)\n",
      "  8. Recommended Paper ID: 590 (Similarity: 0.9510)\n",
      "  9. Recommended Paper ID: 221 (Similarity: 0.9509)\n",
      "  10. Recommended Paper ID: 312 (Similarity: 0.9508)\n",
      "\n",
      "Test Paper 50:\n",
      "  1. Recommended Paper ID: 590 (Similarity: 0.9519)\n",
      "  2. Recommended Paper ID: 221 (Similarity: 0.9499)\n",
      "  3. Recommended Paper ID: 562 (Similarity: 0.9491)\n",
      "  4. Recommended Paper ID: 108 (Similarity: 0.9490)\n",
      "  5. Recommended Paper ID: 68 (Similarity: 0.9488)\n",
      "  6. Recommended Paper ID: 435 (Similarity: 0.9488)\n",
      "  7. Recommended Paper ID: 180 (Similarity: 0.9488)\n",
      "  8. Recommended Paper ID: 227 (Similarity: 0.9486)\n",
      "  9. Recommended Paper ID: 559 (Similarity: 0.9479)\n",
      "  10. Recommended Paper ID: 184 (Similarity: 0.9474)\n",
      "\n",
      "Test Paper 51:\n",
      "  1. Recommended Paper ID: 214 (Similarity: 0.9380)\n",
      "  2. Recommended Paper ID: 119 (Similarity: 0.9371)\n",
      "  3. Recommended Paper ID: 41 (Similarity: 0.9344)\n",
      "  4. Recommended Paper ID: 341 (Similarity: 0.9328)\n",
      "  5. Recommended Paper ID: 489 (Similarity: 0.9319)\n",
      "  6. Recommended Paper ID: 30 (Similarity: 0.9314)\n",
      "  7. Recommended Paper ID: 65 (Similarity: 0.9309)\n",
      "  8. Recommended Paper ID: 440 (Similarity: 0.9308)\n",
      "  9. Recommended Paper ID: 496 (Similarity: 0.9301)\n",
      "  10. Recommended Paper ID: 299 (Similarity: 0.9282)\n",
      "\n",
      "Test Paper 52:\n",
      "  1. Recommended Paper ID: 199 (Similarity: 0.9446)\n",
      "  2. Recommended Paper ID: 311 (Similarity: 0.9430)\n",
      "  3. Recommended Paper ID: 285 (Similarity: 0.9421)\n",
      "  4. Recommended Paper ID: 14 (Similarity: 0.9416)\n",
      "  5. Recommended Paper ID: 435 (Similarity: 0.9410)\n",
      "  6. Recommended Paper ID: 176 (Similarity: 0.9394)\n",
      "  7. Recommended Paper ID: 278 (Similarity: 0.9384)\n",
      "  8. Recommended Paper ID: 258 (Similarity: 0.9383)\n",
      "  9. Recommended Paper ID: 275 (Similarity: 0.9383)\n",
      "  10. Recommended Paper ID: 431 (Similarity: 0.9379)\n",
      "\n",
      "Test Paper 53:\n",
      "  1. Recommended Paper ID: 530 (Similarity: 0.8685)\n",
      "  2. Recommended Paper ID: 61 (Similarity: 0.8626)\n",
      "  3. Recommended Paper ID: 395 (Similarity: 0.8622)\n",
      "  4. Recommended Paper ID: 562 (Similarity: 0.8618)\n",
      "  5. Recommended Paper ID: 106 (Similarity: 0.8616)\n",
      "  6. Recommended Paper ID: 597 (Similarity: 0.8597)\n",
      "  7. Recommended Paper ID: 227 (Similarity: 0.8581)\n",
      "  8. Recommended Paper ID: 512 (Similarity: 0.8571)\n",
      "  9. Recommended Paper ID: 513 (Similarity: 0.8571)\n",
      "  10. Recommended Paper ID: 459 (Similarity: 0.8569)\n",
      "\n",
      "Test Paper 54:\n",
      "  1. Recommended Paper ID: 23 (Similarity: 0.9231)\n",
      "  2. Recommended Paper ID: 310 (Similarity: 0.9201)\n",
      "  3. Recommended Paper ID: 184 (Similarity: 0.9194)\n",
      "  4. Recommended Paper ID: 327 (Similarity: 0.9192)\n",
      "  5. Recommended Paper ID: 529 (Similarity: 0.9183)\n",
      "  6. Recommended Paper ID: 353 (Similarity: 0.9178)\n",
      "  7. Recommended Paper ID: 544 (Similarity: 0.9177)\n",
      "  8. Recommended Paper ID: 61 (Similarity: 0.9172)\n",
      "  9. Recommended Paper ID: 377 (Similarity: 0.9171)\n",
      "  10. Recommended Paper ID: 558 (Similarity: 0.9165)\n",
      "\n",
      "Test Paper 55:\n",
      "  1. Recommended Paper ID: 577 (Similarity: 0.8555)\n",
      "  2. Recommended Paper ID: 445 (Similarity: 0.8498)\n",
      "  3. Recommended Paper ID: 312 (Similarity: 0.8480)\n",
      "  4. Recommended Paper ID: 98 (Similarity: 0.8460)\n",
      "  5. Recommended Paper ID: 212 (Similarity: 0.8447)\n",
      "  6. Recommended Paper ID: 479 (Similarity: 0.8423)\n",
      "  7. Recommended Paper ID: 328 (Similarity: 0.8418)\n",
      "  8. Recommended Paper ID: 527 (Similarity: 0.8408)\n",
      "  9. Recommended Paper ID: 395 (Similarity: 0.8385)\n",
      "  10. Recommended Paper ID: 68 (Similarity: 0.8342)\n",
      "\n",
      "Test Paper 56:\n",
      "  1. Recommended Paper ID: 163 (Similarity: 0.8747)\n",
      "  2. Recommended Paper ID: 527 (Similarity: 0.8729)\n",
      "  3. Recommended Paper ID: 100 (Similarity: 0.8701)\n",
      "  4. Recommended Paper ID: 513 (Similarity: 0.8696)\n",
      "  5. Recommended Paper ID: 14 (Similarity: 0.8690)\n",
      "  6. Recommended Paper ID: 98 (Similarity: 0.8680)\n",
      "  7. Recommended Paper ID: 53 (Similarity: 0.8677)\n",
      "  8. Recommended Paper ID: 435 (Similarity: 0.8672)\n",
      "  9. Recommended Paper ID: 303 (Similarity: 0.8670)\n",
      "  10. Recommended Paper ID: 312 (Similarity: 0.8660)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for all papers using the trained model\n",
    "def get_embeddings(dataloader, model):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    paper_indices = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "            attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "            batch_embeddings = model(input_ids, attention_mask)  # Keep as CUDA tensor\n",
    "            embeddings.append(batch_embeddings)  # Store without converting to NumPy\n",
    "            paper_indices.extend(batch[\"paper_index\"].numpy())\n",
    "\n",
    "    return torch.cat(embeddings, dim=0), np.array(paper_indices)  # Return PyTorch tensor\n",
    "\n",
    "# Get embeddings for train and test sets\n",
    "train_dataloader = DataLoader(PaperDataset(X_train, tokenizer, 256), batch_size=8, shuffle=False)\n",
    "test_dataloader = DataLoader(PaperDataset(X_test, tokenizer, 256), batch_size=8, shuffle=False)\n",
    "\n",
    "train_embeddings, train_indices = get_embeddings(train_dataloader, model)\n",
    "test_embeddings, test_indices = get_embeddings(test_dataloader, model)\n",
    "\n",
    "# Compute cosine similarity in CUDA\n",
    "train_embeddings = F.normalize(train_embeddings, p=2, dim=1)  # Normalize embeddings\n",
    "test_embeddings = F.normalize(test_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sample Test Embedding:\", test_embeddings[0][:15])  # First 15 values\n",
    "print(\"Sample Train Embedding:\", train_embeddings[0][:15])  # First 15 values\n",
    "\n",
    "similarity_matrix = torch.matmul(test_embeddings, train_embeddings.T).cpu().numpy()  # Cosine similarity\n",
    "\n",
    "# Select top-N most similar papers\n",
    "top_n = 10\n",
    "top_indices = np.argsort(-similarity_matrix, axis=1)[:, :top_n]\n",
    "\n",
    "# Print recommended papers\n",
    "recommended_paper_ids = []\n",
    "\n",
    "for i, test_idx in enumerate(top_indices):\n",
    "    recommended_for_test = []\n",
    "    print(f\"\\nTest Paper {i+1}:\")\n",
    "    \n",
    "    for j, train_idx in enumerate(test_idx):\n",
    "        recommended_paper_id = X_train.iloc[train_indices[train_idx]][\"Id\"]\n",
    "        recommended_for_test.append(recommended_paper_id)\n",
    "        \n",
    "        print(f\"  {j+1}. Recommended Paper ID: {recommended_paper_id} (Similarity: {similarity_matrix[i, train_idx]:.4f})\")\n",
    "    \n",
    "    recommended_paper_ids.append(recommended_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af7a75-f560-4fce-84d8-c483c7855b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
