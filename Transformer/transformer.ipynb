{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d664a8f3-deb0-47ee-96dd-4a094ba076f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\steph\\miniforge3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60393e37-8f4c-4abc-866f-024d0d1d697c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (385, 8), Validation: (110, 8), Test: (56, 8)\n"
     ]
    }
   ],
   "source": [
    "# train 70%, val 20%, test 10%\n",
    "df = pd.read_csv(\"database_clean.csv\")\n",
    "df = df.dropna(subset=['title', 'abstract'])\n",
    "#df = df.head(400)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, X_temp = train_test_split(df, test_size=0.3, random_state=42)\n",
    "X_val, X_test = train_test_split(X_temp, test_size=1/3, random_state=42)\n",
    "print(f\"Train: {X_train.shape}, Validation: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0718d3bf-0782-450d-8a8b-ef1130b0bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/distiluse-base-multilingual-cased-v1\")\n",
    "\n",
    "class PaperDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title = str(self.data.iloc[idx][\"title\"])\n",
    "        abstract = str(self.data.iloc[idx][\"abstract\"])\n",
    "        input_text = title + \" \" + abstract  # Combine title and abstract\n",
    "        \n",
    "        tokens = self.tokenizer(\n",
    "            input_text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": tokens[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": tokens[\"attention_mask\"].squeeze(0),\n",
    "            \"paper_index\": idx  # Used for retrieval\n",
    "        }\n",
    "\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "dataset_train = PaperDataset(X_train, tokenizer, 256)\n",
    "dataloader = DataLoader(dataset_train, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f242b441-9990-4523-92cc-243e5fa7facb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Input IDs Shape: torch.Size([8, 256])\n",
      "Batch Attention Mask Shape: torch.Size([8, 256])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(\"Batch Input IDs Shape:\", batch[\"input_ids\"].shape)\n",
    "    print(\"Batch Attention Mask Shape:\", batch[\"attention_mask\"].shape)\n",
    "    break  # Check only the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50964c3e-9433-4a3a-8fa7-40b5575ca93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperRecommender(nn.Module):\n",
    "    def __init__(self, model_name=\"sentence-transformers/distiluse-base-multilingual-cased-v1\", embedding_dim=768, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.fc = nn.Linear(self.embedding_dim, embedding_dim)  # Projection layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.normalize = nn.functional.normalize  # L2 normalization for retrieval\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        input_ids = input_ids.to(next(self.parameters()).device)  # Ensure inputs are on the same device as the model\n",
    "        attention_mask = attention_mask.to(next(self.parameters()).device)\n",
    "        \n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # CLS token representation\n",
    "        embedding = self.fc(self.dropout(pooled_output))\n",
    "        return self.normalize(embedding, p=2, dim=1)  # Normalize embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3558e342-5329-4e21-b2fd-36a7a60540dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0750, 0.0598,  ..., 0.0521, 0.0948, 0.0936],\n",
      "        [0.0750, 1.0000, 0.0727,  ..., 0.0725, 0.0826, 0.0915],\n",
      "        [0.0598, 0.0727, 1.0000,  ..., 0.0706, 0.0856, 0.0740],\n",
      "        ...,\n",
      "        [0.0521, 0.0725, 0.0706,  ..., 1.0000, 0.0538, 0.0668],\n",
      "        [0.0948, 0.0826, 0.0856,  ..., 0.0538, 1.0000, 0.1076],\n",
      "        [0.0936, 0.0915, 0.0740,  ..., 0.0668, 0.1076, 1.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([[ True, False, False,  ..., False,  True,  True],\n",
      "        [False,  True, False,  ..., False,  True,  True],\n",
      "        [False, False,  True,  ..., False,  True, False],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True, False, False],\n",
      "        [ True,  True,  True,  ..., False,  True,  True],\n",
      "        [ True,  True, False,  ..., False,  True,  True]], device='cuda:0')\n",
      "tensor([[False,  True,  True,  ...,  True, False, False],\n",
      "        [ True, False,  True,  ...,  True, False, False],\n",
      "        [ True,  True, False,  ...,  True, False,  True],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False,  True,  True],\n",
      "        [False, False, False,  ...,  True, False, False],\n",
      "        [False, False,  True,  ...,  True, False, False]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def compute_tfidf_similarity(df):\n",
    "    corpus = df['title'] + \" \" + df['abstract']\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    return similarity_matrix\n",
    "\n",
    "similarity_matrix = compute_tfidf_similarity(df)\n",
    "# Convert to tensor for GPU computation\n",
    "similarity_matrix = torch.tensor(similarity_matrix, dtype=torch.float32).to(\"cuda\")\n",
    "print(similarity_matrix)\n",
    "\n",
    "threshold = 0.0785\n",
    "\n",
    "positive_pairs = similarity_matrix > threshold\n",
    "negative_pairs = ~positive_pairs\n",
    "print(positive_pairs)\n",
    "print(negative_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9619723-25a6-49e5-ab88-42fea483e730",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Zero loss at epoch 1. Debug required.\n",
      "Epoch 1, Avg Loss: 0.3925\n",
      "Epoch 2, Avg Loss: 0.3717\n",
      "Epoch 3, Avg Loss: 0.3610\n",
      "Epoch 4, Avg Loss: 0.3470\n",
      "Epoch 5, Avg Loss: 0.3437\n",
      "Epoch 6, Avg Loss: 0.3293\n",
      "Warning: Zero loss at epoch 7. Debug required.\n",
      "Epoch 7, Avg Loss: 0.3034\n",
      "Warning: Zero loss at epoch 8. Debug required.\n",
      "Epoch 8, Avg Loss: 0.2916\n",
      "Warning: Zero loss at epoch 9. Debug required.\n",
      "Epoch 9, Avg Loss: 0.2927\n",
      "Warning: Zero loss at epoch 10. Debug required.\n",
      "Epoch 10, Avg Loss: 0.2669\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = PaperRecommender().to(\"cuda\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "def contrastive_loss(embeddings, similarity_matrix, indices, margin=0.5):\n",
    "    \"\"\"\n",
    "    Contrastive loss using TF-IDF similarity as ground truth.\n",
    "    \n",
    "    embeddings: (batch_size, embedding_dim)\n",
    "    similarity_matrix: Precomputed TF-IDF cosine similarity.\n",
    "    indices: Indices of batch samples in dataset.\n",
    "    margin: Margin for contrastive loss.\n",
    "    \"\"\"\n",
    "    batch_size = embeddings.shape[0]\n",
    "\n",
    "    # Ensure embeddings are L2 normalized\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = torch.mm(embeddings, embeddings.T)  # (batch_size, batch_size)\n",
    "    cosine_distances = 1 - cosine_sim  # Convert similarity to distance\n",
    "\n",
    "    # Extract ground truth similarity values for batch samples\n",
    "    ground_truth_similarities = similarity_matrix[indices][:, indices]\n",
    "\n",
    "    # Define positive and negative pairs\n",
    "    threshold = 0.0785  # Adjust this value if needed\n",
    "    positive_pairs = (ground_truth_similarities > threshold).float()\n",
    "    negative_pairs = (ground_truth_similarities <= threshold).float()\n",
    "\n",
    "    # Compute losses\n",
    "    positive_loss = (cosine_distances * positive_pairs).sum() / (positive_pairs.sum() + 1e-8)\n",
    "    negative_loss = torch.clamp(margin - cosine_distances, min=0) * negative_pairs\n",
    "    negative_loss = negative_loss.sum() / (negative_pairs.sum() + 1e-8)\n",
    "\n",
    "    loss = positive_loss + negative_loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "        indices = batch[\"paper_index\"].cpu().numpy()  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(input_ids, attention_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = contrastive_loss(embeddings, similarity_matrix, indices, margin=0.5)\n",
    "        \n",
    "        if loss.item() == 0:\n",
    "            print(f\"Warning: Zero loss at epoch {epoch+1}. Debug required.\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Avg Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b1bddb-dea3-4a5d-9e80-3da76064b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_papers(query, model, df, top_k=5):\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize and encode query\n",
    "    query_tokens = tokenizer(query, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        query_embedding = model(query_tokens[\"input_ids\"], query_tokens[\"attention_mask\"]).cpu().numpy()\n",
    "\n",
    "    # Compute Euclidean distances between query and all paper embeddings\n",
    "    paper_embeddings = []\n",
    "    paper_indices = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch_input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        batch_attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch_input_ids, batch_attention_mask).cpu().numpy()\n",
    "            paper_embeddings.append(batch_embeddings)\n",
    "            paper_indices.extend(batch[\"paper_index\"].numpy())  # Store original indices\n",
    "\n",
    "    paper_embeddings = np.vstack(paper_embeddings)  # Stack all embeddings\n",
    "    paper_indices = np.array(paper_indices)\n",
    "\n",
    "    # Compute pairwise Euclidean distances\n",
    "    distances = np.linalg.norm(paper_embeddings - query_embedding, axis=1)\n",
    "\n",
    "    # Get top-k closest papers (smallest distances)\n",
    "    top_indices = np.argsort(distances)[:top_k]\n",
    "\n",
    "    print(\"\\nRecommended Papers:\")\n",
    "    for idx in top_indices:\n",
    "        paper_idx = paper_indices[idx]\n",
    "        print(f\"Title: {df.iloc[paper_idx]['title']}\\nAbstract: {df.iloc[paper_idx]['abstract']}\\nDistance: {distances[idx]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a25f812-4c97-4260-a369-d4a766f40744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended Papers:\n",
      "Title: Automated Software Test Data Generation With Generative Adversarial Networks\n",
      "Abstract: With the rapid increase of software scale and complexity, the cost of traditional software testing methods will increase faster than the scale of software. In order to improve test efficiency, it is particularly important to automatically generate high-quality test cases. This paper introduces a framework for automatic test data generation based on the generative adversarial network (GAN). GAN is employed to train a generative model over execution path information to learn the behavior of the software. Then we can use the trained generative model to produce new test data, and select the test data that can improve the branch coverage according to our proposed selection strategy. Compared to prior work, our proposed method is able to handle programs under test with large-scale branches without analyzing branch expressions. In the experiment, we exhibit the performance of our method by using two modules in GNU Scientific Library. In particular, we consider the application of our method in two testing scenarios; unit testing and integration testing, and conduct a series of experiments to compare the performance of three types of GAN models. Results indicate that the WGAN-GP shows the best performance in our framework. Compared with the random testing method, the WGAN-GP based framework improves the test coverage of five functions out of the seven in the unit testing.\n",
      "Distance: 0.9722\n",
      "\n",
      "Title: A Deep Learning Approach for IoT Traffic Multi-Classification in a Smart-City Scenario\n",
      "Abstract: As the number of Internet of Things (IoT) devices and applications increases, the capacity of the IoT access networks is considerably stressed. This can create significant performance bottlenecks in various layers of an end-to-end communication path, including the scheduling of the spectrum, the resource requirements for processing the IoT data at the Edge and/or Cloud, and the attainable delay for critical emergency scenarios. Thus, a proper classification or prediction of the time varying traffic characteristics of the IoT devices is required. However, this classification remains at large an open challenge. Most of the existing solutions are based on machine learning techniques, which nonetheless present high computational cost, whereas they are not considering the fine-grained flow characteristics of the traffic. To this end, this paper introduces the following four contributions. Firstly, we provide an extended feature set including, flow, packet and device level features to characterize the IoT devices in the context of a smart environment. Secondly, we propose a custom weighting based preprocessing algorithm to determine the importance of the data values. Thirdly, we present insights into traffic characteristics using feature selection and correlation mechanisms. Finally, we develop a two-stage learning algorithm and we demonstrate its ability to accurately categorize the IoT devices in two different datasets. The evaluation results show that the proposed learning framework achieves 99.9% accuracy for the first dataset and 99.8% accuracy for the second. Additionally, for the first dataset we achieve a precision and recall performance of 99.6% and 99.5%, while for the second dataset the precission and recall attained is of 99.6% and 99.7% respectively. These results show that our approach clearly outperforms other well-known machine learning methods. Hence, this work provides a useful model deployed in a realistic IoT scenario, where IoT traffic and devices’ pr...\n",
      "Distance: 0.9794\n",
      "\n",
      "Title: Assessment of Damping Control Using Maximum Power Point Tracking Methods for Heaving Wave Energy Converters\n",
      "Abstract: There are not many studies conducted in the implementation of maximum power point tracking (MPPT) methods for heaving wave energy converters (WECs). An assessment of damping control using various MPPT methods for heaving WEC was conducted in this study. Damping control was implemented using a DC–DC boost converter. The duty cycle for MPPT was determined using a perturb and observe algorithm. This assessment study determines the following for applying MPPT for heaving WECs: best location for the observing parameters; best performance index for the MPPT; and effect of averaging the performance index. Three locations for the observing parameters (mechanical parameters near the source, electrical parameters at the load, and electrical parameters between the source and load) and three performance indices (maximising power, minimising impedance, and maximising admittance) were assessed and evaluated. Finally, the effects of applying the running mean and conventional instantaneous value on the performance index were compared. Various scenarios using nine MPPT methods were tested using simulated regular and irregular sea states. The test results were validated experimentally using a simple and low-cost hardware-in-the-loop (HIL) scheme. The HIL scheme was developed using off-the-shelf devices that can be used for any topology of WECs. The results showed that the MPPT method has an optimum performance by using the performance index for maximising power, using observing parameters between the source and the load, and deploying conventional instantaneous values for the observing parameters.\n",
      "Distance: 0.9848\n",
      "\n",
      "Title: A Matheuristic Algorithm for the Multiple-Depot Vehicle and Crew Scheduling Problem\n",
      "Abstract: This work addresses the multiple-depot vehicle and crew scheduling problem (MDVCSP). In MDVCSP, we deal with two NP-hard problems in an integrated way: the multiple-depot vehicle scheduling problem (MDVSP) and the crew scheduling problem (CSP). For solving the MDVCSP, we define the vehicles’ operational routine and the workdays of the crews of a public bus transport system with multiple depots. Given the difficulty of solving real-world instances of the MDVCSP using exact mathematical methods, we propose a matheuristic algorithm for solving it. This matheuristic algorithm combines two strategies into an iterated local search (ILS) based framework: a branch-and-bound algorithm for solving the MDVSP and a variable neighborhood descent (VND) based algorithm for treating the associated CSPs. We compared the proposed ILS-MDVCSP with five approaches in the literature that use the same benchmark test instances. We also solved a real-world problem of one of Brazil’s largest cities. For this problem, we proposed a formulation based on a time-space network to address the MDVSP subproblem. The results obtained showed the effectiveness of ILS-MDVCSP, mainly to deal with real-world and large-scale problems. The algorithm was able to solve the largest instances from the literature, for which there was no reported solution. Regarding the run time, as the instances’ size increases, our approach becomes substantially less costly than the others from the literature. For the Brazilian instances, the ILS-MDVCSP saved, on average, the use of 12 vehicles per day and reduced by up to 15% the daily operational time of the vehicles.\n",
      "Distance: 0.9858\n",
      "\n",
      "Title: Emergency Pull-Over Algorithm for Level 4 Autonomous Vehicles Based on Model-Free Adaptive Feedback Control With Sensitivity and Learning Approaches\n",
      "Abstract: This paper presents an emergency pullover algorithm for fail-safe systems designed for level-4 autonomous vehicles. The proposed algorithm utilizes feedback gain adaptation, based on sensitivity estimation, and cost-based learning. Vehicle failure within this paper does not encompass every type of failure and refers only to any situation where the upper controller or communications from the upper controller shuts down. When this type of failure occurs, the algorithm performs an emergency pullover maneuver. This maneuver does not require any form of independent control from the driver to be performed successfully. However, the highest control priority is still given to the driver if the driver intervenes during the maneuver. The feedback gain adaptation is comprised of two sections: Sensitivity Estimation and Gradient Descent (GD) based Adaptation. For Sensitivity Estimation, a relationship function has been designed with feedback gain, from the feedback gain adaptation, and changes in state error. The sensitivity of state error with respect to feedback gain can then be estimated. This estimation is done through the Recursive Least Squares (RLS) method with multiple forgetting factors through the directional forgetting method. For GD based Adaptation, state errors are applied with parameters for the cost-based learning to give Adaptation Gains. These Adaptation Gains are used in tandem with the estimated sensitivity to update the feedback gain. To reduce the number of tuning parameters required in the GD method, an additional distance condition has been proposed. This condition utilizes feedback change rates and state errors, obtained from the multi-dimensional plane of the feedback gain’s change rates. A proportional coefficient is also required as a tuning parameter for this condition. This parameter is tuned by a cost-based learning algorithm, also designed in this study. Resultantly, these methods allow the adaptive feedback controller to forgo any system informa...\n",
      "Distance: 0.9907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommend_papers(\"deep learning for edge computing\", model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3bd8b34-d743-441f-8b39-6b8162e06224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Test Embedding: tensor([ 0.0412, -0.0199, -0.0312,  0.0079,  0.0086, -0.0558,  0.0416, -0.0383,\n",
      "        -0.1401,  0.0331, -0.0152,  0.0166,  0.0149, -0.0541, -0.0188],\n",
      "       device='cuda:0')\n",
      "Sample Train Embedding: tensor([ 0.0310, -0.0439, -0.0171, -0.0420, -0.0154, -0.0615,  0.0401, -0.0684,\n",
      "        -0.0966, -0.0058, -0.0105,  0.0442,  0.0455, -0.0300, -0.0260],\n",
      "       device='cuda:0')\n",
      "\n",
      "Test Paper 1:\n",
      "  1. Recommended Paper ID: 180 (Similarity: 0.8937)\n",
      "  2. Recommended Paper ID: 144 (Similarity: 0.8934)\n",
      "  3. Recommended Paper ID: 331 (Similarity: 0.8930)\n",
      "  4. Recommended Paper ID: 379 (Similarity: 0.8926)\n",
      "  5. Recommended Paper ID: 53 (Similarity: 0.8918)\n",
      "  6. Recommended Paper ID: 109 (Similarity: 0.8913)\n",
      "  7. Recommended Paper ID: 299 (Similarity: 0.8908)\n",
      "  8. Recommended Paper ID: 529 (Similarity: 0.8907)\n",
      "  9. Recommended Paper ID: 583 (Similarity: 0.8905)\n",
      "  10. Recommended Paper ID: 512 (Similarity: 0.8905)\n",
      "\n",
      "Test Paper 2:\n",
      "  1. Recommended Paper ID: 432 (Similarity: 0.9299)\n",
      "  2. Recommended Paper ID: 531 (Similarity: 0.9088)\n",
      "  3. Recommended Paper ID: 375 (Similarity: 0.9067)\n",
      "  4. Recommended Paper ID: 200 (Similarity: 0.9054)\n",
      "  5. Recommended Paper ID: 562 (Similarity: 0.8857)\n",
      "  6. Recommended Paper ID: 114 (Similarity: 0.8834)\n",
      "  7. Recommended Paper ID: 522 (Similarity: 0.8825)\n",
      "  8. Recommended Paper ID: 238 (Similarity: 0.8783)\n",
      "  9. Recommended Paper ID: 181 (Similarity: 0.8763)\n",
      "  10. Recommended Paper ID: 47 (Similarity: 0.8746)\n",
      "\n",
      "Test Paper 3:\n",
      "  1. Recommended Paper ID: 379 (Similarity: 0.9528)\n",
      "  2. Recommended Paper ID: 494 (Similarity: 0.9512)\n",
      "  3. Recommended Paper ID: 159 (Similarity: 0.9484)\n",
      "  4. Recommended Paper ID: 583 (Similarity: 0.9479)\n",
      "  5. Recommended Paper ID: 329 (Similarity: 0.9469)\n",
      "  6. Recommended Paper ID: 297 (Similarity: 0.9468)\n",
      "  7. Recommended Paper ID: 478 (Similarity: 0.9461)\n",
      "  8. Recommended Paper ID: 495 (Similarity: 0.9458)\n",
      "  9. Recommended Paper ID: 294 (Similarity: 0.9455)\n",
      "  10. Recommended Paper ID: 590 (Similarity: 0.9455)\n",
      "\n",
      "Test Paper 4:\n",
      "  1. Recommended Paper ID: 174 (Similarity: 0.9101)\n",
      "  2. Recommended Paper ID: 462 (Similarity: 0.9078)\n",
      "  3. Recommended Paper ID: 511 (Similarity: 0.9069)\n",
      "  4. Recommended Paper ID: 199 (Similarity: 0.9048)\n",
      "  5. Recommended Paper ID: 331 (Similarity: 0.9041)\n",
      "  6. Recommended Paper ID: 50 (Similarity: 0.9026)\n",
      "  7. Recommended Paper ID: 320 (Similarity: 0.9020)\n",
      "  8. Recommended Paper ID: 418 (Similarity: 0.9017)\n",
      "  9. Recommended Paper ID: 4 (Similarity: 0.9015)\n",
      "  10. Recommended Paper ID: 91 (Similarity: 0.9007)\n",
      "\n",
      "Test Paper 5:\n",
      "  1. Recommended Paper ID: 495 (Similarity: 0.9718)\n",
      "  2. Recommended Paper ID: 94 (Similarity: 0.9712)\n",
      "  3. Recommended Paper ID: 481 (Similarity: 0.9709)\n",
      "  4. Recommended Paper ID: 384 (Similarity: 0.9701)\n",
      "  5. Recommended Paper ID: 494 (Similarity: 0.9700)\n",
      "  6. Recommended Paper ID: 14 (Similarity: 0.9696)\n",
      "  7. Recommended Paper ID: 320 (Similarity: 0.9686)\n",
      "  8. Recommended Paper ID: 583 (Similarity: 0.9685)\n",
      "  9. Recommended Paper ID: 448 (Similarity: 0.9680)\n",
      "  10. Recommended Paper ID: 383 (Similarity: 0.9676)\n",
      "\n",
      "Test Paper 6:\n",
      "  1. Recommended Paper ID: 504 (Similarity: 0.8704)\n",
      "  2. Recommended Paper ID: 91 (Similarity: 0.8676)\n",
      "  3. Recommended Paper ID: 478 (Similarity: 0.8643)\n",
      "  4. Recommended Paper ID: 493 (Similarity: 0.8630)\n",
      "  5. Recommended Paper ID: 180 (Similarity: 0.8628)\n",
      "  6. Recommended Paper ID: 23 (Similarity: 0.8604)\n",
      "  7. Recommended Paper ID: 285 (Similarity: 0.8602)\n",
      "  8. Recommended Paper ID: 300 (Similarity: 0.8590)\n",
      "  9. Recommended Paper ID: 529 (Similarity: 0.8589)\n",
      "  10. Recommended Paper ID: 199 (Similarity: 0.8588)\n",
      "\n",
      "Test Paper 7:\n",
      "  1. Recommended Paper ID: 530 (Similarity: 0.9561)\n",
      "  2. Recommended Paper ID: 448 (Similarity: 0.9523)\n",
      "  3. Recommended Paper ID: 180 (Similarity: 0.9521)\n",
      "  4. Recommended Paper ID: 493 (Similarity: 0.9498)\n",
      "  5. Recommended Paper ID: 163 (Similarity: 0.9489)\n",
      "  6. Recommended Paper ID: 5 (Similarity: 0.9484)\n",
      "  7. Recommended Paper ID: 98 (Similarity: 0.9484)\n",
      "  8. Recommended Paper ID: 327 (Similarity: 0.9479)\n",
      "  9. Recommended Paper ID: 303 (Similarity: 0.9473)\n",
      "  10. Recommended Paper ID: 331 (Similarity: 0.9469)\n",
      "\n",
      "Test Paper 8:\n",
      "  1. Recommended Paper ID: 14 (Similarity: 0.8997)\n",
      "  2. Recommended Paper ID: 443 (Similarity: 0.8995)\n",
      "  3. Recommended Paper ID: 320 (Similarity: 0.8966)\n",
      "  4. Recommended Paper ID: 557 (Similarity: 0.8966)\n",
      "  5. Recommended Paper ID: 583 (Similarity: 0.8964)\n",
      "  6. Recommended Paper ID: 294 (Similarity: 0.8958)\n",
      "  7. Recommended Paper ID: 477 (Similarity: 0.8936)\n",
      "  8. Recommended Paper ID: 43 (Similarity: 0.8933)\n",
      "  9. Recommended Paper ID: 494 (Similarity: 0.8932)\n",
      "  10. Recommended Paper ID: 507 (Similarity: 0.8921)\n",
      "\n",
      "Test Paper 9:\n",
      "  1. Recommended Paper ID: 148 (Similarity: 0.9200)\n",
      "  2. Recommended Paper ID: 583 (Similarity: 0.9184)\n",
      "  3. Recommended Paper ID: 559 (Similarity: 0.9171)\n",
      "  4. Recommended Paper ID: 495 (Similarity: 0.9166)\n",
      "  5. Recommended Paper ID: 557 (Similarity: 0.9150)\n",
      "  6. Recommended Paper ID: 556 (Similarity: 0.9133)\n",
      "  7. Recommended Paper ID: 516 (Similarity: 0.9125)\n",
      "  8. Recommended Paper ID: 331 (Similarity: 0.9121)\n",
      "  9. Recommended Paper ID: 61 (Similarity: 0.9120)\n",
      "  10. Recommended Paper ID: 227 (Similarity: 0.9120)\n",
      "\n",
      "Test Paper 10:\n",
      "  1. Recommended Paper ID: 583 (Similarity: 0.9528)\n",
      "  2. Recommended Paper ID: 495 (Similarity: 0.9524)\n",
      "  3. Recommended Paper ID: 379 (Similarity: 0.9509)\n",
      "  4. Recommended Paper ID: 152 (Similarity: 0.9502)\n",
      "  5. Recommended Paper ID: 327 (Similarity: 0.9492)\n",
      "  6. Recommended Paper ID: 557 (Similarity: 0.9489)\n",
      "  7. Recommended Paper ID: 419 (Similarity: 0.9488)\n",
      "  8. Recommended Paper ID: 283 (Similarity: 0.9483)\n",
      "  9. Recommended Paper ID: 383 (Similarity: 0.9474)\n",
      "  10. Recommended Paper ID: 479 (Similarity: 0.9474)\n",
      "\n",
      "Test Paper 11:\n",
      "  1. Recommended Paper ID: 279 (Similarity: 0.9709)\n",
      "  2. Recommended Paper ID: 5 (Similarity: 0.9667)\n",
      "  3. Recommended Paper ID: 566 (Similarity: 0.9664)\n",
      "  4. Recommended Paper ID: 495 (Similarity: 0.9656)\n",
      "  5. Recommended Paper ID: 498 (Similarity: 0.9653)\n",
      "  6. Recommended Paper ID: 289 (Similarity: 0.9649)\n",
      "  7. Recommended Paper ID: 544 (Similarity: 0.9647)\n",
      "  8. Recommended Paper ID: 383 (Similarity: 0.9645)\n",
      "  9. Recommended Paper ID: 379 (Similarity: 0.9644)\n",
      "  10. Recommended Paper ID: 452 (Similarity: 0.9643)\n",
      "\n",
      "Test Paper 12:\n",
      "  1. Recommended Paper ID: 320 (Similarity: 0.8944)\n",
      "  2. Recommended Paper ID: 583 (Similarity: 0.8916)\n",
      "  3. Recommended Paper ID: 227 (Similarity: 0.8874)\n",
      "  4. Recommended Paper ID: 504 (Similarity: 0.8867)\n",
      "  5. Recommended Paper ID: 94 (Similarity: 0.8845)\n",
      "  6. Recommended Paper ID: 14 (Similarity: 0.8845)\n",
      "  7. Recommended Paper ID: 294 (Similarity: 0.8842)\n",
      "  8. Recommended Paper ID: 327 (Similarity: 0.8828)\n",
      "  9. Recommended Paper ID: 152 (Similarity: 0.8828)\n",
      "  10. Recommended Paper ID: 312 (Similarity: 0.8826)\n",
      "\n",
      "Test Paper 13:\n",
      "  1. Recommended Paper ID: 496 (Similarity: 0.8786)\n",
      "  2. Recommended Paper ID: 369 (Similarity: 0.8782)\n",
      "  3. Recommended Paper ID: 435 (Similarity: 0.8779)\n",
      "  4. Recommended Paper ID: 119 (Similarity: 0.8772)\n",
      "  5. Recommended Paper ID: 311 (Similarity: 0.8759)\n",
      "  6. Recommended Paper ID: 238 (Similarity: 0.8751)\n",
      "  7. Recommended Paper ID: 120 (Similarity: 0.8745)\n",
      "  8. Recommended Paper ID: 226 (Similarity: 0.8721)\n",
      "  9. Recommended Paper ID: 464 (Similarity: 0.8694)\n",
      "  10. Recommended Paper ID: 594 (Similarity: 0.8684)\n",
      "\n",
      "Test Paper 14:\n",
      "  1. Recommended Paper ID: 19 (Similarity: 0.9482)\n",
      "  2. Recommended Paper ID: 331 (Similarity: 0.9115)\n",
      "  3. Recommended Paper ID: 34 (Similarity: 0.9107)\n",
      "  4. Recommended Paper ID: 23 (Similarity: 0.9101)\n",
      "  5. Recommended Paper ID: 516 (Similarity: 0.9099)\n",
      "  6. Recommended Paper ID: 180 (Similarity: 0.9097)\n",
      "  7. Recommended Paper ID: 590 (Similarity: 0.9097)\n",
      "  8. Recommended Paper ID: 185 (Similarity: 0.9082)\n",
      "  9. Recommended Paper ID: 184 (Similarity: 0.9071)\n",
      "  10. Recommended Paper ID: 406 (Similarity: 0.9069)\n",
      "\n",
      "Test Paper 15:\n",
      "  1. Recommended Paper ID: 50 (Similarity: 0.9122)\n",
      "  2. Recommended Paper ID: 297 (Similarity: 0.9106)\n",
      "  3. Recommended Paper ID: 489 (Similarity: 0.9105)\n",
      "  4. Recommended Paper ID: 91 (Similarity: 0.9095)\n",
      "  5. Recommended Paper ID: 5 (Similarity: 0.9093)\n",
      "  6. Recommended Paper ID: 97 (Similarity: 0.9089)\n",
      "  7. Recommended Paper ID: 65 (Similarity: 0.9087)\n",
      "  8. Recommended Paper ID: 163 (Similarity: 0.9083)\n",
      "  9. Recommended Paper ID: 174 (Similarity: 0.9078)\n",
      "  10. Recommended Paper ID: 379 (Similarity: 0.9069)\n",
      "\n",
      "Test Paper 16:\n",
      "  1. Recommended Paper ID: 174 (Similarity: 0.8959)\n",
      "  2. Recommended Paper ID: 331 (Similarity: 0.8933)\n",
      "  3. Recommended Paper ID: 556 (Similarity: 0.8931)\n",
      "  4. Recommended Paper ID: 180 (Similarity: 0.8914)\n",
      "  5. Recommended Paper ID: 550 (Similarity: 0.8905)\n",
      "  6. Recommended Paper ID: 395 (Similarity: 0.8898)\n",
      "  7. Recommended Paper ID: 495 (Similarity: 0.8895)\n",
      "  8. Recommended Paper ID: 163 (Similarity: 0.8884)\n",
      "  9. Recommended Paper ID: 124 (Similarity: 0.8879)\n",
      "  10. Recommended Paper ID: 34 (Similarity: 0.8878)\n",
      "\n",
      "Test Paper 17:\n",
      "  1. Recommended Paper ID: 118 (Similarity: 0.9478)\n",
      "  2. Recommended Paper ID: 563 (Similarity: 0.9478)\n",
      "  3. Recommended Paper ID: 544 (Similarity: 0.9474)\n",
      "  4. Recommended Paper ID: 327 (Similarity: 0.9469)\n",
      "  5. Recommended Paper ID: 384 (Similarity: 0.9468)\n",
      "  6. Recommended Paper ID: 230 (Similarity: 0.9466)\n",
      "  7. Recommended Paper ID: 383 (Similarity: 0.9465)\n",
      "  8. Recommended Paper ID: 507 (Similarity: 0.9464)\n",
      "  9. Recommended Paper ID: 495 (Similarity: 0.9462)\n",
      "  10. Recommended Paper ID: 589 (Similarity: 0.9455)\n",
      "\n",
      "Test Paper 18:\n",
      "  1. Recommended Paper ID: 577 (Similarity: 0.7396)\n",
      "  2. Recommended Paper ID: 91 (Similarity: 0.7350)\n",
      "  3. Recommended Paper ID: 219 (Similarity: 0.7337)\n",
      "  4. Recommended Paper ID: 137 (Similarity: 0.7335)\n",
      "  5. Recommended Paper ID: 216 (Similarity: 0.7322)\n",
      "  6. Recommended Paper ID: 38 (Similarity: 0.7302)\n",
      "  7. Recommended Paper ID: 297 (Similarity: 0.7297)\n",
      "  8. Recommended Paper ID: 504 (Similarity: 0.7291)\n",
      "  9. Recommended Paper ID: 148 (Similarity: 0.7285)\n",
      "  10. Recommended Paper ID: 300 (Similarity: 0.7275)\n",
      "\n",
      "Test Paper 19:\n",
      "  1. Recommended Paper ID: 137 (Similarity: 0.9151)\n",
      "  2. Recommended Paper ID: 297 (Similarity: 0.9150)\n",
      "  3. Recommended Paper ID: 478 (Similarity: 0.9139)\n",
      "  4. Recommended Paper ID: 283 (Similarity: 0.9123)\n",
      "  5. Recommended Paper ID: 331 (Similarity: 0.9113)\n",
      "  6. Recommended Paper ID: 294 (Similarity: 0.9111)\n",
      "  7. Recommended Paper ID: 556 (Similarity: 0.9096)\n",
      "  8. Recommended Paper ID: 312 (Similarity: 0.9096)\n",
      "  9. Recommended Paper ID: 379 (Similarity: 0.9095)\n",
      "  10. Recommended Paper ID: 184 (Similarity: 0.9090)\n",
      "\n",
      "Test Paper 20:\n",
      "  1. Recommended Paper ID: 377 (Similarity: 0.8416)\n",
      "  2. Recommended Paper ID: 590 (Similarity: 0.8373)\n",
      "  3. Recommended Paper ID: 281 (Similarity: 0.8368)\n",
      "  4. Recommended Paper ID: 44 (Similarity: 0.8363)\n",
      "  5. Recommended Paper ID: 358 (Similarity: 0.8356)\n",
      "  6. Recommended Paper ID: 120 (Similarity: 0.8353)\n",
      "  7. Recommended Paper ID: 294 (Similarity: 0.8353)\n",
      "  8. Recommended Paper ID: 538 (Similarity: 0.8331)\n",
      "  9. Recommended Paper ID: 5 (Similarity: 0.8296)\n",
      "  10. Recommended Paper ID: 94 (Similarity: 0.8292)\n",
      "\n",
      "Test Paper 21:\n",
      "  1. Recommended Paper ID: 199 (Similarity: 0.8935)\n",
      "  2. Recommended Paper ID: 283 (Similarity: 0.8890)\n",
      "  3. Recommended Paper ID: 152 (Similarity: 0.8877)\n",
      "  4. Recommended Paper ID: 180 (Similarity: 0.8872)\n",
      "  5. Recommended Paper ID: 294 (Similarity: 0.8859)\n",
      "  6. Recommended Paper ID: 331 (Similarity: 0.8858)\n",
      "  7. Recommended Paper ID: 328 (Similarity: 0.8830)\n",
      "  8. Recommended Paper ID: 590 (Similarity: 0.8827)\n",
      "  9. Recommended Paper ID: 478 (Similarity: 0.8827)\n",
      "  10. Recommended Paper ID: 137 (Similarity: 0.8805)\n",
      "\n",
      "Test Paper 22:\n",
      "  1. Recommended Paper ID: 383 (Similarity: 0.9812)\n",
      "  2. Recommended Paper ID: 109 (Similarity: 0.9803)\n",
      "  3. Recommended Paper ID: 544 (Similarity: 0.9780)\n",
      "  4. Recommended Paper ID: 184 (Similarity: 0.9778)\n",
      "  5. Recommended Paper ID: 180 (Similarity: 0.9771)\n",
      "  6. Recommended Paper ID: 5 (Similarity: 0.9771)\n",
      "  7. Recommended Paper ID: 327 (Similarity: 0.9763)\n",
      "  8. Recommended Paper ID: 589 (Similarity: 0.9760)\n",
      "  9. Recommended Paper ID: 126 (Similarity: 0.9759)\n",
      "  10. Recommended Paper ID: 478 (Similarity: 0.9758)\n",
      "\n",
      "Test Paper 23:\n",
      "  1. Recommended Paper ID: 116 (Similarity: 0.8867)\n",
      "  2. Recommended Paper ID: 4 (Similarity: 0.8853)\n",
      "  3. Recommended Paper ID: 16 (Similarity: 0.8851)\n",
      "  4. Recommended Paper ID: 181 (Similarity: 0.8781)\n",
      "  5. Recommended Paper ID: 327 (Similarity: 0.8769)\n",
      "  6. Recommended Paper ID: 510 (Similarity: 0.8767)\n",
      "  7. Recommended Paper ID: 566 (Similarity: 0.8767)\n",
      "  8. Recommended Paper ID: 124 (Similarity: 0.8760)\n",
      "  9. Recommended Paper ID: 394 (Similarity: 0.8758)\n",
      "  10. Recommended Paper ID: 445 (Similarity: 0.8757)\n",
      "\n",
      "Test Paper 24:\n",
      "  1. Recommended Paper ID: 30 (Similarity: 0.9128)\n",
      "  2. Recommended Paper ID: 116 (Similarity: 0.9042)\n",
      "  3. Recommended Paper ID: 16 (Similarity: 0.8852)\n",
      "  4. Recommended Paper ID: 552 (Similarity: 0.8702)\n",
      "  5. Recommended Paper ID: 275 (Similarity: 0.8663)\n",
      "  6. Recommended Paper ID: 455 (Similarity: 0.8629)\n",
      "  7. Recommended Paper ID: 394 (Similarity: 0.8586)\n",
      "  8. Recommended Paper ID: 311 (Similarity: 0.8570)\n",
      "  9. Recommended Paper ID: 440 (Similarity: 0.8527)\n",
      "  10. Recommended Paper ID: 459 (Similarity: 0.8527)\n",
      "\n",
      "Test Paper 25:\n",
      "  1. Recommended Paper ID: 199 (Similarity: 0.9206)\n",
      "  2. Recommended Paper ID: 479 (Similarity: 0.9184)\n",
      "  3. Recommended Paper ID: 119 (Similarity: 0.9168)\n",
      "  4. Recommended Paper ID: 452 (Similarity: 0.9150)\n",
      "  5. Recommended Paper ID: 297 (Similarity: 0.9144)\n",
      "  6. Recommended Paper ID: 180 (Similarity: 0.9144)\n",
      "  7. Recommended Paper ID: 98 (Similarity: 0.9143)\n",
      "  8. Recommended Paper ID: 345 (Similarity: 0.9136)\n",
      "  9. Recommended Paper ID: 152 (Similarity: 0.9124)\n",
      "  10. Recommended Paper ID: 331 (Similarity: 0.9116)\n",
      "\n",
      "Test Paper 26:\n",
      "  1. Recommended Paper ID: 258 (Similarity: 0.9777)\n",
      "  2. Recommended Paper ID: 327 (Similarity: 0.9704)\n",
      "  3. Recommended Paper ID: 53 (Similarity: 0.9689)\n",
      "  4. Recommended Paper ID: 395 (Similarity: 0.9685)\n",
      "  5. Recommended Paper ID: 184 (Similarity: 0.9684)\n",
      "  6. Recommended Paper ID: 174 (Similarity: 0.9681)\n",
      "  7. Recommended Paper ID: 544 (Similarity: 0.9675)\n",
      "  8. Recommended Paper ID: 163 (Similarity: 0.9675)\n",
      "  9. Recommended Paper ID: 180 (Similarity: 0.9673)\n",
      "  10. Recommended Paper ID: 459 (Similarity: 0.9672)\n",
      "\n",
      "Test Paper 27:\n",
      "  1. Recommended Paper ID: 527 (Similarity: 0.9172)\n",
      "  2. Recommended Paper ID: 94 (Similarity: 0.9077)\n",
      "  3. Recommended Paper ID: 379 (Similarity: 0.9067)\n",
      "  4. Recommended Paper ID: 297 (Similarity: 0.9054)\n",
      "  5. Recommended Paper ID: 64 (Similarity: 0.9049)\n",
      "  6. Recommended Paper ID: 5 (Similarity: 0.9037)\n",
      "  7. Recommended Paper ID: 279 (Similarity: 0.9018)\n",
      "  8. Recommended Paper ID: 345 (Similarity: 0.9016)\n",
      "  9. Recommended Paper ID: 311 (Similarity: 0.9015)\n",
      "  10. Recommended Paper ID: 53 (Similarity: 0.9011)\n",
      "\n",
      "Test Paper 28:\n",
      "  1. Recommended Paper ID: 111 (Similarity: 0.9619)\n",
      "  2. Recommended Paper ID: 452 (Similarity: 0.9617)\n",
      "  3. Recommended Paper ID: 97 (Similarity: 0.9607)\n",
      "  4. Recommended Paper ID: 557 (Similarity: 0.9601)\n",
      "  5. Recommended Paper ID: 478 (Similarity: 0.9601)\n",
      "  6. Recommended Paper ID: 559 (Similarity: 0.9590)\n",
      "  7. Recommended Paper ID: 5 (Similarity: 0.9585)\n",
      "  8. Recommended Paper ID: 383 (Similarity: 0.9583)\n",
      "  9. Recommended Paper ID: 127 (Similarity: 0.9577)\n",
      "  10. Recommended Paper ID: 359 (Similarity: 0.9576)\n",
      "\n",
      "Test Paper 29:\n",
      "  1. Recommended Paper ID: 152 (Similarity: 0.9335)\n",
      "  2. Recommended Paper ID: 345 (Similarity: 0.9290)\n",
      "  3. Recommended Paper ID: 557 (Similarity: 0.9253)\n",
      "  4. Recommended Paper ID: 583 (Similarity: 0.9227)\n",
      "  5. Recommended Paper ID: 510 (Similarity: 0.9222)\n",
      "  6. Recommended Paper ID: 589 (Similarity: 0.9219)\n",
      "  7. Recommended Paper ID: 379 (Similarity: 0.9217)\n",
      "  8. Recommended Paper ID: 199 (Similarity: 0.9214)\n",
      "  9. Recommended Paper ID: 479 (Similarity: 0.9207)\n",
      "  10. Recommended Paper ID: 383 (Similarity: 0.9206)\n",
      "\n",
      "Test Paper 30:\n",
      "  1. Recommended Paper ID: 431 (Similarity: 0.9030)\n",
      "  2. Recommended Paper ID: 297 (Similarity: 0.8806)\n",
      "  3. Recommended Paper ID: 152 (Similarity: 0.8799)\n",
      "  4. Recommended Paper ID: 61 (Similarity: 0.8745)\n",
      "  5. Recommended Paper ID: 294 (Similarity: 0.8743)\n",
      "  6. Recommended Paper ID: 283 (Similarity: 0.8735)\n",
      "  7. Recommended Paper ID: 176 (Similarity: 0.8734)\n",
      "  8. Recommended Paper ID: 285 (Similarity: 0.8731)\n",
      "  9. Recommended Paper ID: 320 (Similarity: 0.8723)\n",
      "  10. Recommended Paper ID: 495 (Similarity: 0.8714)\n",
      "\n",
      "Test Paper 31:\n",
      "  1. Recommended Paper ID: 527 (Similarity: 0.8847)\n",
      "  2. Recommended Paper ID: 431 (Similarity: 0.8813)\n",
      "  3. Recommended Paper ID: 495 (Similarity: 0.8807)\n",
      "  4. Recommended Paper ID: 68 (Similarity: 0.8800)\n",
      "  5. Recommended Paper ID: 297 (Similarity: 0.8798)\n",
      "  6. Recommended Paper ID: 180 (Similarity: 0.8794)\n",
      "  7. Recommended Paper ID: 4 (Similarity: 0.8789)\n",
      "  8. Recommended Paper ID: 566 (Similarity: 0.8786)\n",
      "  9. Recommended Paper ID: 345 (Similarity: 0.8781)\n",
      "  10. Recommended Paper ID: 377 (Similarity: 0.8775)\n",
      "\n",
      "Test Paper 32:\n",
      "  1. Recommended Paper ID: 5 (Similarity: 0.9651)\n",
      "  2. Recommended Paper ID: 327 (Similarity: 0.9638)\n",
      "  3. Recommended Paper ID: 557 (Similarity: 0.9630)\n",
      "  4. Recommended Paper ID: 23 (Similarity: 0.9620)\n",
      "  5. Recommended Paper ID: 495 (Similarity: 0.9617)\n",
      "  6. Recommended Paper ID: 47 (Similarity: 0.9609)\n",
      "  7. Recommended Paper ID: 126 (Similarity: 0.9608)\n",
      "  8. Recommended Paper ID: 94 (Similarity: 0.9603)\n",
      "  9. Recommended Paper ID: 294 (Similarity: 0.9597)\n",
      "  10. Recommended Paper ID: 109 (Similarity: 0.9592)\n",
      "\n",
      "Test Paper 33:\n",
      "  1. Recommended Paper ID: 279 (Similarity: 0.9654)\n",
      "  2. Recommended Paper ID: 266 (Similarity: 0.9604)\n",
      "  3. Recommended Paper ID: 495 (Similarity: 0.9603)\n",
      "  4. Recommended Paper ID: 97 (Similarity: 0.9600)\n",
      "  5. Recommended Paper ID: 379 (Similarity: 0.9588)\n",
      "  6. Recommended Paper ID: 558 (Similarity: 0.9588)\n",
      "  7. Recommended Paper ID: 557 (Similarity: 0.9586)\n",
      "  8. Recommended Paper ID: 94 (Similarity: 0.9585)\n",
      "  9. Recommended Paper ID: 258 (Similarity: 0.9584)\n",
      "  10. Recommended Paper ID: 498 (Similarity: 0.9583)\n",
      "\n",
      "Test Paper 34:\n",
      "  1. Recommended Paper ID: 327 (Similarity: 0.9667)\n",
      "  2. Recommended Paper ID: 478 (Similarity: 0.9665)\n",
      "  3. Recommended Paper ID: 383 (Similarity: 0.9663)\n",
      "  4. Recommended Paper ID: 97 (Similarity: 0.9657)\n",
      "  5. Recommended Paper ID: 479 (Similarity: 0.9657)\n",
      "  6. Recommended Paper ID: 495 (Similarity: 0.9651)\n",
      "  7. Recommended Paper ID: 180 (Similarity: 0.9645)\n",
      "  8. Recommended Paper ID: 65 (Similarity: 0.9634)\n",
      "  9. Recommended Paper ID: 218 (Similarity: 0.9633)\n",
      "  10. Recommended Paper ID: 331 (Similarity: 0.9629)\n",
      "\n",
      "Test Paper 35:\n",
      "  1. Recommended Paper ID: 329 (Similarity: 0.9203)\n",
      "  2. Recommended Paper ID: 38 (Similarity: 0.9134)\n",
      "  3. Recommended Paper ID: 379 (Similarity: 0.9125)\n",
      "  4. Recommended Paper ID: 386 (Similarity: 0.9115)\n",
      "  5. Recommended Paper ID: 109 (Similarity: 0.9102)\n",
      "  6. Recommended Paper ID: 94 (Similarity: 0.9092)\n",
      "  7. Recommended Paper ID: 144 (Similarity: 0.9078)\n",
      "  8. Recommended Paper ID: 5 (Similarity: 0.9063)\n",
      "  9. Recommended Paper ID: 590 (Similarity: 0.9059)\n",
      "  10. Recommended Paper ID: 180 (Similarity: 0.9059)\n",
      "\n",
      "Test Paper 36:\n",
      "  1. Recommended Paper ID: 590 (Similarity: 0.9215)\n",
      "  2. Recommended Paper ID: 94 (Similarity: 0.9208)\n",
      "  3. Recommended Paper ID: 180 (Similarity: 0.9174)\n",
      "  4. Recommended Paper ID: 379 (Similarity: 0.9174)\n",
      "  5. Recommended Paper ID: 44 (Similarity: 0.9162)\n",
      "  6. Recommended Paper ID: 294 (Similarity: 0.9161)\n",
      "  7. Recommended Paper ID: 530 (Similarity: 0.9155)\n",
      "  8. Recommended Paper ID: 297 (Similarity: 0.9153)\n",
      "  9. Recommended Paper ID: 494 (Similarity: 0.9151)\n",
      "  10. Recommended Paper ID: 266 (Similarity: 0.9146)\n",
      "\n",
      "Test Paper 37:\n",
      "  1. Recommended Paper ID: 383 (Similarity: 0.9508)\n",
      "  2. Recommended Paper ID: 97 (Similarity: 0.9504)\n",
      "  3. Recommended Paper ID: 492 (Similarity: 0.9493)\n",
      "  4. Recommended Paper ID: 108 (Similarity: 0.9493)\n",
      "  5. Recommended Paper ID: 199 (Similarity: 0.9489)\n",
      "  6. Recommended Paper ID: 507 (Similarity: 0.9488)\n",
      "  7. Recommended Paper ID: 452 (Similarity: 0.9476)\n",
      "  8. Recommended Paper ID: 327 (Similarity: 0.9466)\n",
      "  9. Recommended Paper ID: 478 (Similarity: 0.9466)\n",
      "  10. Recommended Paper ID: 320 (Similarity: 0.9464)\n",
      "\n",
      "Test Paper 38:\n",
      "  1. Recommended Paper ID: 200 (Similarity: 0.8016)\n",
      "  2. Recommended Paper ID: 4 (Similarity: 0.7987)\n",
      "  3. Recommended Paper ID: 163 (Similarity: 0.7915)\n",
      "  4. Recommended Paper ID: 114 (Similarity: 0.7908)\n",
      "  5. Recommended Paper ID: 562 (Similarity: 0.7903)\n",
      "  6. Recommended Paper ID: 50 (Similarity: 0.7898)\n",
      "  7. Recommended Paper ID: 559 (Similarity: 0.7897)\n",
      "  8. Recommended Paper ID: 418 (Similarity: 0.7871)\n",
      "  9. Recommended Paper ID: 505 (Similarity: 0.7863)\n",
      "  10. Recommended Paper ID: 445 (Similarity: 0.7861)\n",
      "\n",
      "Test Paper 39:\n",
      "  1. Recommended Paper ID: 551 (Similarity: 0.7416)\n",
      "  2. Recommended Paper ID: 342 (Similarity: 0.7250)\n",
      "  3. Recommended Paper ID: 74 (Similarity: 0.7075)\n",
      "  4. Recommended Paper ID: 365 (Similarity: 0.7068)\n",
      "  5. Recommended Paper ID: 165 (Similarity: 0.6988)\n",
      "  6. Recommended Paper ID: 531 (Similarity: 0.6940)\n",
      "  7. Recommended Paper ID: 121 (Similarity: 0.6888)\n",
      "  8. Recommended Paper ID: 125 (Similarity: 0.6861)\n",
      "  9. Recommended Paper ID: 222 (Similarity: 0.6799)\n",
      "  10. Recommended Paper ID: 525 (Similarity: 0.6780)\n",
      "\n",
      "Test Paper 40:\n",
      "  1. Recommended Paper ID: 231 (Similarity: 0.8193)\n",
      "  2. Recommended Paper ID: 556 (Similarity: 0.8120)\n",
      "  3. Recommended Paper ID: 559 (Similarity: 0.8098)\n",
      "  4. Recommended Paper ID: 505 (Similarity: 0.8078)\n",
      "  5. Recommended Paper ID: 174 (Similarity: 0.8073)\n",
      "  6. Recommended Paper ID: 297 (Similarity: 0.8053)\n",
      "  7. Recommended Paper ID: 370 (Similarity: 0.8051)\n",
      "  8. Recommended Paper ID: 283 (Similarity: 0.8047)\n",
      "  9. Recommended Paper ID: 156 (Similarity: 0.8044)\n",
      "  10. Recommended Paper ID: 457 (Similarity: 0.8041)\n",
      "\n",
      "Test Paper 41:\n",
      "  1. Recommended Paper ID: 227 (Similarity: 0.9118)\n",
      "  2. Recommended Paper ID: 294 (Similarity: 0.9102)\n",
      "  3. Recommended Paper ID: 478 (Similarity: 0.9049)\n",
      "  4. Recommended Paper ID: 310 (Similarity: 0.9043)\n",
      "  5. Recommended Paper ID: 137 (Similarity: 0.9029)\n",
      "  6. Recommended Paper ID: 126 (Similarity: 0.9028)\n",
      "  7. Recommended Paper ID: 23 (Similarity: 0.9024)\n",
      "  8. Recommended Paper ID: 556 (Similarity: 0.9022)\n",
      "  9. Recommended Paper ID: 199 (Similarity: 0.9022)\n",
      "  10. Recommended Paper ID: 14 (Similarity: 0.9013)\n",
      "\n",
      "Test Paper 42:\n",
      "  1. Recommended Paper ID: 127 (Similarity: 0.8878)\n",
      "  2. Recommended Paper ID: 47 (Similarity: 0.8858)\n",
      "  3. Recommended Paper ID: 119 (Similarity: 0.8766)\n",
      "  4. Recommended Paper ID: 379 (Similarity: 0.8765)\n",
      "  5. Recommended Paper ID: 226 (Similarity: 0.8764)\n",
      "  6. Recommended Paper ID: 23 (Similarity: 0.8759)\n",
      "  7. Recommended Paper ID: 367 (Similarity: 0.8755)\n",
      "  8. Recommended Paper ID: 557 (Similarity: 0.8750)\n",
      "  9. Recommended Paper ID: 50 (Similarity: 0.8745)\n",
      "  10. Recommended Paper ID: 454 (Similarity: 0.8744)\n",
      "\n",
      "Test Paper 43:\n",
      "  1. Recommended Paper ID: 180 (Similarity: 0.9193)\n",
      "  2. Recommended Paper ID: 163 (Similarity: 0.9123)\n",
      "  3. Recommended Paper ID: 119 (Similarity: 0.9100)\n",
      "  4. Recommended Paper ID: 179 (Similarity: 0.9084)\n",
      "  5. Recommended Paper ID: 109 (Similarity: 0.9068)\n",
      "  6. Recommended Paper ID: 23 (Similarity: 0.9066)\n",
      "  7. Recommended Paper ID: 516 (Similarity: 0.9056)\n",
      "  8. Recommended Paper ID: 124 (Similarity: 0.9053)\n",
      "  9. Recommended Paper ID: 502 (Similarity: 0.9051)\n",
      "  10. Recommended Paper ID: 14 (Similarity: 0.9044)\n",
      "\n",
      "Test Paper 44:\n",
      "  1. Recommended Paper ID: 289 (Similarity: 0.9343)\n",
      "  2. Recommended Paper ID: 218 (Similarity: 0.9316)\n",
      "  3. Recommended Paper ID: 510 (Similarity: 0.9316)\n",
      "  4. Recommended Paper ID: 300 (Similarity: 0.9311)\n",
      "  5. Recommended Paper ID: 192 (Similarity: 0.9302)\n",
      "  6. Recommended Paper ID: 114 (Similarity: 0.9301)\n",
      "  7. Recommended Paper ID: 383 (Similarity: 0.9298)\n",
      "  8. Recommended Paper ID: 481 (Similarity: 0.9297)\n",
      "  9. Recommended Paper ID: 452 (Similarity: 0.9295)\n",
      "  10. Recommended Paper ID: 97 (Similarity: 0.9295)\n",
      "\n",
      "Test Paper 45:\n",
      "  1. Recommended Paper ID: 53 (Similarity: 0.9342)\n",
      "  2. Recommended Paper ID: 180 (Similarity: 0.9331)\n",
      "  3. Recommended Paper ID: 445 (Similarity: 0.9324)\n",
      "  4. Recommended Paper ID: 258 (Similarity: 0.9309)\n",
      "  5. Recommended Paper ID: 459 (Similarity: 0.9308)\n",
      "  6. Recommended Paper ID: 174 (Similarity: 0.9305)\n",
      "  7. Recommended Paper ID: 566 (Similarity: 0.9295)\n",
      "  8. Recommended Paper ID: 184 (Similarity: 0.9294)\n",
      "  9. Recommended Paper ID: 514 (Similarity: 0.9289)\n",
      "  10. Recommended Paper ID: 119 (Similarity: 0.9288)\n",
      "\n",
      "Test Paper 46:\n",
      "  1. Recommended Paper ID: 208 (Similarity: 0.8430)\n",
      "  2. Recommended Paper ID: 299 (Similarity: 0.8415)\n",
      "  3. Recommended Paper ID: 529 (Similarity: 0.8408)\n",
      "  4. Recommended Paper ID: 19 (Similarity: 0.8402)\n",
      "  5. Recommended Paper ID: 91 (Similarity: 0.8358)\n",
      "  6. Recommended Paper ID: 180 (Similarity: 0.8354)\n",
      "  7. Recommended Paper ID: 303 (Similarity: 0.8327)\n",
      "  8. Recommended Paper ID: 23 (Similarity: 0.8319)\n",
      "  9. Recommended Paper ID: 484 (Similarity: 0.8319)\n",
      "  10. Recommended Paper ID: 179 (Similarity: 0.8314)\n",
      "\n",
      "Test Paper 47:\n",
      "  1. Recommended Paper ID: 531 (Similarity: 0.8779)\n",
      "  2. Recommended Paper ID: 432 (Similarity: 0.8627)\n",
      "  3. Recommended Paper ID: 200 (Similarity: 0.8537)\n",
      "  4. Recommended Paper ID: 562 (Similarity: 0.8486)\n",
      "  5. Recommended Paper ID: 375 (Similarity: 0.8482)\n",
      "  6. Recommended Paper ID: 522 (Similarity: 0.8419)\n",
      "  7. Recommended Paper ID: 114 (Similarity: 0.8325)\n",
      "  8. Recommended Paper ID: 457 (Similarity: 0.8300)\n",
      "  9. Recommended Paper ID: 111 (Similarity: 0.8273)\n",
      "  10. Recommended Paper ID: 205 (Similarity: 0.8261)\n",
      "\n",
      "Test Paper 48:\n",
      "  1. Recommended Paper ID: 418 (Similarity: 0.9554)\n",
      "  2. Recommended Paper ID: 98 (Similarity: 0.9548)\n",
      "  3. Recommended Paper ID: 556 (Similarity: 0.9538)\n",
      "  4. Recommended Paper ID: 199 (Similarity: 0.9518)\n",
      "  5. Recommended Paper ID: 312 (Similarity: 0.9518)\n",
      "  6. Recommended Paper ID: 379 (Similarity: 0.9517)\n",
      "  7. Recommended Paper ID: 163 (Similarity: 0.9516)\n",
      "  8. Recommended Paper ID: 297 (Similarity: 0.9515)\n",
      "  9. Recommended Paper ID: 289 (Similarity: 0.9513)\n",
      "  10. Recommended Paper ID: 218 (Similarity: 0.9510)\n",
      "\n",
      "Test Paper 49:\n",
      "  1. Recommended Paper ID: 498 (Similarity: 0.9680)\n",
      "  2. Recommended Paper ID: 109 (Similarity: 0.9677)\n",
      "  3. Recommended Paper ID: 23 (Similarity: 0.9653)\n",
      "  4. Recommended Paper ID: 395 (Similarity: 0.9650)\n",
      "  5. Recommended Paper ID: 53 (Similarity: 0.9647)\n",
      "  6. Recommended Paper ID: 489 (Similarity: 0.9640)\n",
      "  7. Recommended Paper ID: 184 (Similarity: 0.9640)\n",
      "  8. Recommended Paper ID: 445 (Similarity: 0.9638)\n",
      "  9. Recommended Paper ID: 258 (Similarity: 0.9634)\n",
      "  10. Recommended Paper ID: 544 (Similarity: 0.9630)\n",
      "\n",
      "Test Paper 50:\n",
      "  1. Recommended Paper ID: 108 (Similarity: 0.9047)\n",
      "  2. Recommended Paper ID: 488 (Similarity: 0.9038)\n",
      "  3. Recommended Paper ID: 498 (Similarity: 0.9025)\n",
      "  4. Recommended Paper ID: 590 (Similarity: 0.9008)\n",
      "  5. Recommended Paper ID: 495 (Similarity: 0.9001)\n",
      "  6. Recommended Paper ID: 180 (Similarity: 0.8978)\n",
      "  7. Recommended Paper ID: 258 (Similarity: 0.8966)\n",
      "  8. Recommended Paper ID: 559 (Similarity: 0.8960)\n",
      "  9. Recommended Paper ID: 383 (Similarity: 0.8960)\n",
      "  10. Recommended Paper ID: 566 (Similarity: 0.8950)\n",
      "\n",
      "Test Paper 51:\n",
      "  1. Recommended Paper ID: 5 (Similarity: 0.9529)\n",
      "  2. Recommended Paper ID: 238 (Similarity: 0.9528)\n",
      "  3. Recommended Paper ID: 97 (Similarity: 0.9519)\n",
      "  4. Recommended Paper ID: 566 (Similarity: 0.9514)\n",
      "  5. Recommended Paper ID: 289 (Similarity: 0.9513)\n",
      "  6. Recommended Paper ID: 510 (Similarity: 0.9505)\n",
      "  7. Recommended Paper ID: 440 (Similarity: 0.9505)\n",
      "  8. Recommended Paper ID: 109 (Similarity: 0.9503)\n",
      "  9. Recommended Paper ID: 311 (Similarity: 0.9499)\n",
      "  10. Recommended Paper ID: 353 (Similarity: 0.9498)\n",
      "\n",
      "Test Paper 52:\n",
      "  1. Recommended Paper ID: 275 (Similarity: 0.9060)\n",
      "  2. Recommended Paper ID: 30 (Similarity: 0.9055)\n",
      "  3. Recommended Paper ID: 116 (Similarity: 0.9029)\n",
      "  4. Recommended Paper ID: 16 (Similarity: 0.8787)\n",
      "  5. Recommended Paper ID: 394 (Similarity: 0.8775)\n",
      "  6. Recommended Paper ID: 459 (Similarity: 0.8744)\n",
      "  7. Recommended Paper ID: 590 (Similarity: 0.8730)\n",
      "  8. Recommended Paper ID: 566 (Similarity: 0.8708)\n",
      "  9. Recommended Paper ID: 329 (Similarity: 0.8690)\n",
      "  10. Recommended Paper ID: 379 (Similarity: 0.8673)\n",
      "\n",
      "Test Paper 53:\n",
      "  1. Recommended Paper ID: 531 (Similarity: 0.8819)\n",
      "  2. Recommended Paper ID: 114 (Similarity: 0.8771)\n",
      "  3. Recommended Paper ID: 562 (Similarity: 0.8724)\n",
      "  4. Recommended Paper ID: 432 (Similarity: 0.8706)\n",
      "  5. Recommended Paper ID: 457 (Similarity: 0.8699)\n",
      "  6. Recommended Paper ID: 200 (Similarity: 0.8679)\n",
      "  7. Recommended Paper ID: 375 (Similarity: 0.8632)\n",
      "  8. Recommended Paper ID: 522 (Similarity: 0.8609)\n",
      "  9. Recommended Paper ID: 181 (Similarity: 0.8601)\n",
      "  10. Recommended Paper ID: 419 (Similarity: 0.8589)\n",
      "\n",
      "Test Paper 54:\n",
      "  1. Recommended Paper ID: 446 (Similarity: 0.9558)\n",
      "  2. Recommended Paper ID: 557 (Similarity: 0.9551)\n",
      "  3. Recommended Paper ID: 544 (Similarity: 0.9522)\n",
      "  4. Recommended Paper ID: 327 (Similarity: 0.9518)\n",
      "  5. Recommended Paper ID: 452 (Similarity: 0.9515)\n",
      "  6. Recommended Paper ID: 97 (Similarity: 0.9507)\n",
      "  7. Recommended Paper ID: 126 (Similarity: 0.9500)\n",
      "  8. Recommended Paper ID: 478 (Similarity: 0.9496)\n",
      "  9. Recommended Paper ID: 507 (Similarity: 0.9492)\n",
      "  10. Recommended Paper ID: 359 (Similarity: 0.9485)\n",
      "\n",
      "Test Paper 55:\n",
      "  1. Recommended Paper ID: 564 (Similarity: 0.7394)\n",
      "  2. Recommended Paper ID: 491 (Similarity: 0.7330)\n",
      "  3. Recommended Paper ID: 521 (Similarity: 0.7126)\n",
      "  4. Recommended Paper ID: 538 (Similarity: 0.7112)\n",
      "  5. Recommended Paper ID: 312 (Similarity: 0.7097)\n",
      "  6. Recommended Paper ID: 185 (Similarity: 0.7084)\n",
      "  7. Recommended Paper ID: 285 (Similarity: 0.7077)\n",
      "  8. Recommended Paper ID: 176 (Similarity: 0.7060)\n",
      "  9. Recommended Paper ID: 69 (Similarity: 0.7054)\n",
      "  10. Recommended Paper ID: 517 (Similarity: 0.7047)\n",
      "\n",
      "Test Paper 56:\n",
      "  1. Recommended Paper ID: 367 (Similarity: 0.8600)\n",
      "  2. Recommended Paper ID: 185 (Similarity: 0.8552)\n",
      "  3. Recommended Paper ID: 180 (Similarity: 0.8532)\n",
      "  4. Recommended Paper ID: 205 (Similarity: 0.8532)\n",
      "  5. Recommended Paper ID: 176 (Similarity: 0.8517)\n",
      "  6. Recommended Paper ID: 100 (Similarity: 0.8506)\n",
      "  7. Recommended Paper ID: 285 (Similarity: 0.8481)\n",
      "  8. Recommended Paper ID: 489 (Similarity: 0.8478)\n",
      "  9. Recommended Paper ID: 574 (Similarity: 0.8478)\n",
      "  10. Recommended Paper ID: 199 (Similarity: 0.8475)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for all papers using the trained model\n",
    "def get_embeddings(dataloader, model):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    paper_indices = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "            attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "            batch_embeddings = model(input_ids, attention_mask)  # Keep as CUDA tensor\n",
    "            embeddings.append(batch_embeddings)  # Store without converting to NumPy\n",
    "            paper_indices.extend(batch[\"paper_index\"].numpy())\n",
    "\n",
    "    return torch.cat(embeddings, dim=0), np.array(paper_indices)  # Return PyTorch tensor\n",
    "\n",
    "# Get embeddings for train and test sets\n",
    "train_dataloader = DataLoader(PaperDataset(X_train, tokenizer, 256), batch_size=8, shuffle=False)\n",
    "test_dataloader = DataLoader(PaperDataset(X_test, tokenizer, 256), batch_size=8, shuffle=False)\n",
    "\n",
    "train_embeddings, train_indices = get_embeddings(train_dataloader, model)\n",
    "test_embeddings, test_indices = get_embeddings(test_dataloader, model)\n",
    "\n",
    "# Compute cosine similarity in CUDA\n",
    "train_embeddings = F.normalize(train_embeddings, p=2, dim=1)  # Normalize embeddings\n",
    "test_embeddings = F.normalize(test_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sample Test Embedding:\", test_embeddings[0][:15])  # First 15 values\n",
    "print(\"Sample Train Embedding:\", train_embeddings[0][:15])  # First 15 values\n",
    "\n",
    "similarity_matrix = torch.matmul(test_embeddings, train_embeddings.T).cpu().numpy()  # Cosine similarity\n",
    "\n",
    "# Select top-N most similar papers\n",
    "top_n = 10\n",
    "top_indices = np.argsort(-similarity_matrix, axis=1)[:, :top_n]\n",
    "\n",
    "# Print recommended papers\n",
    "recommended_paper_ids = []\n",
    "\n",
    "for i, test_idx in enumerate(top_indices):\n",
    "    recommended_for_test = []\n",
    "    print(f\"\\nTest Paper {i+1}:\")\n",
    "    \n",
    "    for j, train_idx in enumerate(test_idx):\n",
    "        recommended_paper_id = X_train.iloc[train_indices[train_idx]][\"Id\"]\n",
    "        recommended_for_test.append(recommended_paper_id)\n",
    "        \n",
    "        print(f\"  {j+1}. Recommended Paper ID: {recommended_paper_id} (Similarity: {similarity_matrix[i, train_idx]:.4f})\")\n",
    "    \n",
    "    recommended_paper_ids.append(recommended_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af7a75-f560-4fce-84d8-c483c7855b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
